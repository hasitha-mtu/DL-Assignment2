C:\Users\AdikariAdikari\anaconda3\envs\tf\python.exe C:\Users\AdikariAdikari\PycharmProjects\DL-Assignment2\question2.py
[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]
physical_devices : [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]
2.10.1
True
(19200, 64, 64, 3) (19200,)
(4800, 64, 64, 3) (4800,)
========================================resnet50_phase_A===============================================
2025-05-08 15:53:03.769728: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-05-08 15:53:05.150052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8943 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:17:00.0, compute capability: 7.5
2025-05-08 15:53:05.152286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 8943 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5
Model: "resnet50"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to
==================================================================================================
 input_1 (InputLayer)           [(None, 64, 64, 3)]  0           []

 conv1_pad (ZeroPadding2D)      (None, 70, 70, 3)    0           ['input_1[0][0]']

 conv1_conv (Conv2D)            (None, 32, 32, 64)   9472        ['conv1_pad[0][0]']

 conv1_bn (BatchNormalization)  (None, 32, 32, 64)   256         ['conv1_conv[0][0]']

 conv1_relu (Activation)        (None, 32, 32, 64)   0           ['conv1_bn[0][0]']

 pool1_pad (ZeroPadding2D)      (None, 34, 34, 64)   0           ['conv1_relu[0][0]']

 pool1_pool (MaxPooling2D)      (None, 16, 16, 64)   0           ['pool1_pad[0][0]']

 conv2_block1_1_conv (Conv2D)   (None, 16, 16, 64)   4160        ['pool1_pool[0][0]']

 conv2_block1_1_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block1_1_conv[0][0]']
 ization)

 conv2_block1_1_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block1_1_bn[0][0]']
 n)

 conv2_block1_2_conv (Conv2D)   (None, 16, 16, 64)   36928       ['conv2_block1_1_relu[0][0]']

 conv2_block1_2_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block1_2_conv[0][0]']
 ization)

 conv2_block1_2_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block1_2_bn[0][0]']
 n)

 conv2_block1_0_conv (Conv2D)   (None, 16, 16, 256)  16640       ['pool1_pool[0][0]']

 conv2_block1_3_conv (Conv2D)   (None, 16, 16, 256)  16640       ['conv2_block1_2_relu[0][0]']

 conv2_block1_0_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv2_block1_0_conv[0][0]']
 ization)

 conv2_block1_3_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv2_block1_3_conv[0][0]']
 ization)

 conv2_block1_add (Add)         (None, 16, 16, 256)  0           ['conv2_block1_0_bn[0][0]',
                                                                  'conv2_block1_3_bn[0][0]']

 conv2_block1_out (Activation)  (None, 16, 16, 256)  0           ['conv2_block1_add[0][0]']

 conv2_block2_1_conv (Conv2D)   (None, 16, 16, 64)   16448       ['conv2_block1_out[0][0]']

 conv2_block2_1_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block2_1_conv[0][0]']
 ization)

 conv2_block2_1_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block2_1_bn[0][0]']
 n)

 conv2_block2_2_conv (Conv2D)   (None, 16, 16, 64)   36928       ['conv2_block2_1_relu[0][0]']

 conv2_block2_2_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block2_2_conv[0][0]']
 ization)

 conv2_block2_2_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block2_2_bn[0][0]']
 n)

 conv2_block2_3_conv (Conv2D)   (None, 16, 16, 256)  16640       ['conv2_block2_2_relu[0][0]']

 conv2_block2_3_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv2_block2_3_conv[0][0]']
 ization)

 conv2_block2_add (Add)         (None, 16, 16, 256)  0           ['conv2_block1_out[0][0]',
                                                                  'conv2_block2_3_bn[0][0]']

 conv2_block2_out (Activation)  (None, 16, 16, 256)  0           ['conv2_block2_add[0][0]']

 conv2_block3_1_conv (Conv2D)   (None, 16, 16, 64)   16448       ['conv2_block2_out[0][0]']

 conv2_block3_1_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block3_1_conv[0][0]']
 ization)

 conv2_block3_1_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block3_1_bn[0][0]']
 n)

 conv2_block3_2_conv (Conv2D)   (None, 16, 16, 64)   36928       ['conv2_block3_1_relu[0][0]']

 conv2_block3_2_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block3_2_conv[0][0]']
 ization)

 conv2_block3_2_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block3_2_bn[0][0]']
 n)

 conv2_block3_3_conv (Conv2D)   (None, 16, 16, 256)  16640       ['conv2_block3_2_relu[0][0]']

 conv2_block3_3_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv2_block3_3_conv[0][0]']
 ization)

 conv2_block3_add (Add)         (None, 16, 16, 256)  0           ['conv2_block2_out[0][0]',
                                                                  'conv2_block3_3_bn[0][0]']

 conv2_block3_out (Activation)  (None, 16, 16, 256)  0           ['conv2_block3_add[0][0]']

 conv3_block1_1_conv (Conv2D)   (None, 8, 8, 128)    32896       ['conv2_block3_out[0][0]']

 conv3_block1_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block1_1_conv[0][0]']
 ization)

 conv3_block1_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block1_1_bn[0][0]']
 n)

 conv3_block1_2_conv (Conv2D)   (None, 8, 8, 128)    147584      ['conv3_block1_1_relu[0][0]']

 conv3_block1_2_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block1_2_conv[0][0]']
 ization)

 conv3_block1_2_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block1_2_bn[0][0]']
 n)

 conv3_block1_0_conv (Conv2D)   (None, 8, 8, 512)    131584      ['conv2_block3_out[0][0]']

 conv3_block1_3_conv (Conv2D)   (None, 8, 8, 512)    66048       ['conv3_block1_2_relu[0][0]']

 conv3_block1_0_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv3_block1_0_conv[0][0]']
 ization)

 conv3_block1_3_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv3_block1_3_conv[0][0]']
 ization)

 conv3_block1_add (Add)         (None, 8, 8, 512)    0           ['conv3_block1_0_bn[0][0]',
                                                                  'conv3_block1_3_bn[0][0]']

 conv3_block1_out (Activation)  (None, 8, 8, 512)    0           ['conv3_block1_add[0][0]']

 conv3_block2_1_conv (Conv2D)   (None, 8, 8, 128)    65664       ['conv3_block1_out[0][0]']

 conv3_block2_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block2_1_conv[0][0]']
 ization)

 conv3_block2_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block2_1_bn[0][0]']
 n)

 conv3_block2_2_conv (Conv2D)   (None, 8, 8, 128)    147584      ['conv3_block2_1_relu[0][0]']

 conv3_block2_2_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block2_2_conv[0][0]']
 ization)

 conv3_block2_2_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block2_2_bn[0][0]']
 n)

 conv3_block2_3_conv (Conv2D)   (None, 8, 8, 512)    66048       ['conv3_block2_2_relu[0][0]']

 conv3_block2_3_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv3_block2_3_conv[0][0]']
 ization)

 conv3_block2_add (Add)         (None, 8, 8, 512)    0           ['conv3_block1_out[0][0]',
                                                                  'conv3_block2_3_bn[0][0]']

 conv3_block2_out (Activation)  (None, 8, 8, 512)    0           ['conv3_block2_add[0][0]']

 conv3_block3_1_conv (Conv2D)   (None, 8, 8, 128)    65664       ['conv3_block2_out[0][0]']

 conv3_block3_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block3_1_conv[0][0]']
 ization)

 conv3_block3_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block3_1_bn[0][0]']
 n)

 conv3_block3_2_conv (Conv2D)   (None, 8, 8, 128)    147584      ['conv3_block3_1_relu[0][0]']

 conv3_block3_2_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block3_2_conv[0][0]']
 ization)

 conv3_block3_2_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block3_2_bn[0][0]']
 n)

 conv3_block3_3_conv (Conv2D)   (None, 8, 8, 512)    66048       ['conv3_block3_2_relu[0][0]']

 conv3_block3_3_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv3_block3_3_conv[0][0]']
 ization)

 conv3_block3_add (Add)         (None, 8, 8, 512)    0           ['conv3_block2_out[0][0]',
                                                                  'conv3_block3_3_bn[0][0]']

 conv3_block3_out (Activation)  (None, 8, 8, 512)    0           ['conv3_block3_add[0][0]']

 conv3_block4_1_conv (Conv2D)   (None, 8, 8, 128)    65664       ['conv3_block3_out[0][0]']

 conv3_block4_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block4_1_conv[0][0]']
 ization)

 conv3_block4_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block4_1_bn[0][0]']
 n)

 conv3_block4_2_conv (Conv2D)   (None, 8, 8, 128)    147584      ['conv3_block4_1_relu[0][0]']

 conv3_block4_2_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block4_2_conv[0][0]']
 ization)

 conv3_block4_2_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block4_2_bn[0][0]']
 n)

 conv3_block4_3_conv (Conv2D)   (None, 8, 8, 512)    66048       ['conv3_block4_2_relu[0][0]']

 conv3_block4_3_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv3_block4_3_conv[0][0]']
 ization)

 conv3_block4_add (Add)         (None, 8, 8, 512)    0           ['conv3_block3_out[0][0]',
                                                                  'conv3_block4_3_bn[0][0]']

 conv3_block4_out (Activation)  (None, 8, 8, 512)    0           ['conv3_block4_add[0][0]']

 conv4_block1_1_conv (Conv2D)   (None, 4, 4, 256)    131328      ['conv3_block4_out[0][0]']

 conv4_block1_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block1_1_conv[0][0]']
 ization)

 conv4_block1_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block1_1_bn[0][0]']
 n)

 conv4_block1_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block1_1_relu[0][0]']

 conv4_block1_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block1_2_conv[0][0]']
 ization)

 conv4_block1_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block1_2_bn[0][0]']
 n)

 conv4_block1_0_conv (Conv2D)   (None, 4, 4, 1024)   525312      ['conv3_block4_out[0][0]']

 conv4_block1_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block1_2_relu[0][0]']

 conv4_block1_0_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block1_0_conv[0][0]']
 ization)

 conv4_block1_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block1_3_conv[0][0]']
 ization)

 conv4_block1_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block1_0_bn[0][0]',
                                                                  'conv4_block1_3_bn[0][0]']

 conv4_block1_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block1_add[0][0]']

 conv4_block2_1_conv (Conv2D)   (None, 4, 4, 256)    262400      ['conv4_block1_out[0][0]']

 conv4_block2_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block2_1_conv[0][0]']
 ization)

 conv4_block2_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block2_1_bn[0][0]']
 n)

 conv4_block2_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block2_1_relu[0][0]']

 conv4_block2_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block2_2_conv[0][0]']
 ization)

 conv4_block2_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block2_2_bn[0][0]']
 n)

 conv4_block2_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block2_2_relu[0][0]']

 conv4_block2_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block2_3_conv[0][0]']
 ization)

 conv4_block2_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block1_out[0][0]',
                                                                  'conv4_block2_3_bn[0][0]']

 conv4_block2_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block2_add[0][0]']

 conv4_block3_1_conv (Conv2D)   (None, 4, 4, 256)    262400      ['conv4_block2_out[0][0]']

 conv4_block3_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block3_1_conv[0][0]']
 ization)

 conv4_block3_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block3_1_bn[0][0]']
 n)

 conv4_block3_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block3_1_relu[0][0]']

 conv4_block3_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block3_2_conv[0][0]']
 ization)

 conv4_block3_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block3_2_bn[0][0]']
 n)

 conv4_block3_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block3_2_relu[0][0]']

 conv4_block3_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block3_3_conv[0][0]']
 ization)

 conv4_block3_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block2_out[0][0]',
                                                                  'conv4_block3_3_bn[0][0]']

 conv4_block3_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block3_add[0][0]']

 conv4_block4_1_conv (Conv2D)   (None, 4, 4, 256)    262400      ['conv4_block3_out[0][0]']

 conv4_block4_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block4_1_conv[0][0]']
 ization)

 conv4_block4_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block4_1_bn[0][0]']
 n)

 conv4_block4_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block4_1_relu[0][0]']

 conv4_block4_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block4_2_conv[0][0]']
 ization)

 conv4_block4_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block4_2_bn[0][0]']
 n)

 conv4_block4_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block4_2_relu[0][0]']

 conv4_block4_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block4_3_conv[0][0]']
 ization)

 conv4_block4_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block3_out[0][0]',
                                                                  'conv4_block4_3_bn[0][0]']

 conv4_block4_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block4_add[0][0]']

 conv4_block5_1_conv (Conv2D)   (None, 4, 4, 256)    262400      ['conv4_block4_out[0][0]']

 conv4_block5_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block5_1_conv[0][0]']
 ization)

 conv4_block5_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block5_1_bn[0][0]']
 n)

 conv4_block5_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block5_1_relu[0][0]']

 conv4_block5_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block5_2_conv[0][0]']
 ization)

 conv4_block5_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block5_2_bn[0][0]']
 n)

 conv4_block5_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block5_2_relu[0][0]']

 conv4_block5_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block5_3_conv[0][0]']
 ization)

 conv4_block5_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block4_out[0][0]',
                                                                  'conv4_block5_3_bn[0][0]']

 conv4_block5_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block5_add[0][0]']

 conv4_block6_1_conv (Conv2D)   (None, 4, 4, 256)    262400      ['conv4_block5_out[0][0]']

 conv4_block6_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block6_1_conv[0][0]']
 ization)

 conv4_block6_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block6_1_bn[0][0]']
 n)

 conv4_block6_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block6_1_relu[0][0]']

 conv4_block6_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block6_2_conv[0][0]']
 ization)

 conv4_block6_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block6_2_bn[0][0]']
 n)

 conv4_block6_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block6_2_relu[0][0]']

 conv4_block6_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block6_3_conv[0][0]']
 ization)

 conv4_block6_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block5_out[0][0]',
                                                                  'conv4_block6_3_bn[0][0]']

 conv4_block6_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block6_add[0][0]']

 conv5_block1_1_conv (Conv2D)   (None, 2, 2, 512)    524800      ['conv4_block6_out[0][0]']

 conv5_block1_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block1_1_conv[0][0]']
 ization)

 conv5_block1_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block1_1_bn[0][0]']
 n)

 conv5_block1_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block1_1_relu[0][0]']

 conv5_block1_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block1_2_conv[0][0]']
 ization)

 conv5_block1_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block1_2_bn[0][0]']
 n)

 conv5_block1_0_conv (Conv2D)   (None, 2, 2, 2048)   2099200     ['conv4_block6_out[0][0]']

 conv5_block1_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block1_2_relu[0][0]']

 conv5_block1_0_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block1_0_conv[0][0]']
 ization)

 conv5_block1_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block1_3_conv[0][0]']
 ization)

 conv5_block1_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block1_0_bn[0][0]',
                                                                  'conv5_block1_3_bn[0][0]']

 conv5_block1_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block1_add[0][0]']

 conv5_block2_1_conv (Conv2D)   (None, 2, 2, 512)    1049088     ['conv5_block1_out[0][0]']

 conv5_block2_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block2_1_conv[0][0]']
 ization)

 conv5_block2_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block2_1_bn[0][0]']
 n)

 conv5_block2_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block2_1_relu[0][0]']

 conv5_block2_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block2_2_conv[0][0]']
 ization)

 conv5_block2_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block2_2_bn[0][0]']
 n)

 conv5_block2_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block2_2_relu[0][0]']

 conv5_block2_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block2_3_conv[0][0]']
 ization)

 conv5_block2_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block1_out[0][0]',
                                                                  'conv5_block2_3_bn[0][0]']

 conv5_block2_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block2_add[0][0]']

 conv5_block3_1_conv (Conv2D)   (None, 2, 2, 512)    1049088     ['conv5_block2_out[0][0]']

 conv5_block3_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block3_1_conv[0][0]']
 ization)

 conv5_block3_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block3_1_bn[0][0]']
 n)

 conv5_block3_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block3_1_relu[0][0]']

 conv5_block3_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block3_2_conv[0][0]']
 ization)

 conv5_block3_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block3_2_bn[0][0]']
 n)

 conv5_block3_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block3_2_relu[0][0]']

 conv5_block3_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block3_3_conv[0][0]']
 ization)

 conv5_block3_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block2_out[0][0]',
                                                                  'conv5_block3_3_bn[0][0]']

 conv5_block3_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block3_add[0][0]']

 avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']
 2D)

==================================================================================================
Total params: 23,587,712
Trainable params: 0
Non-trainable params: 23,587,712
__________________________________________________________________________________________________
ResNet50 Base model: None
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 input_2 (InputLayer)        [(None, 64, 64, 3)]       0

 data_augmentation (Sequenti  (None, 64, 64, 3)        0
 al)

 tf.__operators__.getitem (S  (None, 64, 64, 3)        0
 licingOpLambda)

 tf.nn.bias_add (TFOpLambda)  (None, 64, 64, 3)        0

 resnet50 (Functional)       (None, 2048)              23587712

 flatten (Flatten)           (None, 2048)              0

 dense (Dense)               (None, 128)               262272

 dropout (Dropout)           (None, 128)               0

 dense_1 (Dense)             (None, 10)                1290

=================================================================
Total params: 23,851,274
Trainable params: 263,562
Non-trainable params: 23,587,712
_________________________________________________________________
ResNet50 Model: None
Epoch 1/25
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input "contrast_factor" of op 'AdjustContrastv2' expected to be loop invariant.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input "contrast_factor" of op 'AdjustContrastv2' expected to be loop invariant.
2025-05-08 15:53:14.070251: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100
600/600 [==============================] - 292s 470ms/step - loss: 1.2749 - accuracy: 0.6149 - val_loss: 0.4233 - val_accuracy: 0.8700
Epoch 2/25
600/600 [==============================] - 292s 487ms/step - loss: 0.6004 - accuracy: 0.8091 - val_loss: 0.3363 - val_accuracy: 0.8923
Epoch 3/25
600/600 [==============================] - 293s 488ms/step - loss: 0.4941 - accuracy: 0.8434 - val_loss: 0.3016 - val_accuracy: 0.9025
Epoch 4/25
600/600 [==============================] - 270s 450ms/step - loss: 0.4445 - accuracy: 0.8566 - val_loss: 0.2797 - val_accuracy: 0.9071
Epoch 5/25
600/600 [==============================] - 287s 479ms/step - loss: 0.4081 - accuracy: 0.8677 - val_loss: 0.2656 - val_accuracy: 0.9115
Epoch 6/25
600/600 [==============================] - 311s 518ms/step - loss: 0.3906 - accuracy: 0.8705 - val_loss: 0.2493 - val_accuracy: 0.9169
Epoch 7/25
600/600 [==============================] - 268s 446ms/step - loss: 0.3636 - accuracy: 0.8820 - val_loss: 0.2401 - val_accuracy: 0.9171
Epoch 8/25
600/600 [==============================] - 287s 479ms/step - loss: 0.3500 - accuracy: 0.8857 - val_loss: 0.2412 - val_accuracy: 0.9187
Epoch 9/25
600/600 [==============================] - 287s 478ms/step - loss: 0.3287 - accuracy: 0.8905 - val_loss: 0.2338 - val_accuracy: 0.9198
Epoch 10/25
600/600 [==============================] - 272s 454ms/step - loss: 0.3188 - accuracy: 0.8954 - val_loss: 0.2270 - val_accuracy: 0.9225
Epoch 11/25
600/600 [==============================] - 269s 449ms/step - loss: 0.3123 - accuracy: 0.8953 - val_loss: 0.2290 - val_accuracy: 0.9219
Epoch 12/25
600/600 [==============================] - 269s 448ms/step - loss: 0.3007 - accuracy: 0.9008 - val_loss: 0.2234 - val_accuracy: 0.9229
Epoch 13/25
600/600 [==============================] - 322s 538ms/step - loss: 0.2885 - accuracy: 0.9028 - val_loss: 0.2122 - val_accuracy: 0.9271
Epoch 14/25
600/600 [==============================] - 336s 561ms/step - loss: 0.2786 - accuracy: 0.9058 - val_loss: 0.2123 - val_accuracy: 0.9273
Epoch 15/25
600/600 [==============================] - 335s 559ms/step - loss: 0.2768 - accuracy: 0.9075 - val_loss: 0.2176 - val_accuracy: 0.9262
Epoch 16/25
600/600 [==============================] - 336s 559ms/step - loss: 0.2700 - accuracy: 0.9080 - val_loss: 0.2103 - val_accuracy: 0.9294
Epoch 17/25
600/600 [==============================] - 333s 555ms/step - loss: 0.2628 - accuracy: 0.9118 - val_loss: 0.2104 - val_accuracy: 0.9287
Epoch 18/25
600/600 [==============================] - 298s 497ms/step - loss: 0.2644 - accuracy: 0.9103 - val_loss: 0.2047 - val_accuracy: 0.9279
Epoch 19/25
600/600 [==============================] - 266s 444ms/step - loss: 0.2562 - accuracy: 0.9145 - val_loss: 0.2093 - val_accuracy: 0.9269
Epoch 20/25
600/600 [==============================] - 269s 448ms/step - loss: 0.2489 - accuracy: 0.9156 - val_loss: 0.2061 - val_accuracy: 0.9290
Epoch 21/25
600/600 [==============================] - 267s 445ms/step - loss: 0.2457 - accuracy: 0.9160 - val_loss: 0.2042 - val_accuracy: 0.9323
Epoch 22/25
600/600 [==============================] - 271s 451ms/step - loss: 0.2445 - accuracy: 0.9174 - val_loss: 0.1964 - val_accuracy: 0.9340
Epoch 23/25
600/600 [==============================] - 309s 516ms/step - loss: 0.2322 - accuracy: 0.9196 - val_loss: 0.2020 - val_accuracy: 0.9283
Epoch 24/25
600/600 [==============================] - 334s 557ms/step - loss: 0.2375 - accuracy: 0.9214 - val_loss: 0.1998 - val_accuracy: 0.9312
Epoch 25/25
600/600 [==============================] - 335s 559ms/step - loss: 0.2296 - accuracy: 0.9224 - val_loss: 0.2024 - val_accuracy: 0.9298
=======================================resnet50_phase_B_1==============================================
Model: "resnet50"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to
==================================================================================================
 input_3 (InputLayer)           [(None, 64, 64, 3)]  0           []

 conv1_pad (ZeroPadding2D)      (None, 70, 70, 3)    0           ['input_3[0][0]']

 conv1_conv (Conv2D)            (None, 32, 32, 64)   9472        ['conv1_pad[0][0]']

 conv1_bn (BatchNormalization)  (None, 32, 32, 64)   256         ['conv1_conv[0][0]']

 conv1_relu (Activation)        (None, 32, 32, 64)   0           ['conv1_bn[0][0]']

 pool1_pad (ZeroPadding2D)      (None, 34, 34, 64)   0           ['conv1_relu[0][0]']

 pool1_pool (MaxPooling2D)      (None, 16, 16, 64)   0           ['pool1_pad[0][0]']

 conv2_block1_1_conv (Conv2D)   (None, 16, 16, 64)   4160        ['pool1_pool[0][0]']

 conv2_block1_1_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block1_1_conv[0][0]']
 ization)

 conv2_block1_1_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block1_1_bn[0][0]']
 n)

 conv2_block1_2_conv (Conv2D)   (None, 16, 16, 64)   36928       ['conv2_block1_1_relu[0][0]']

 conv2_block1_2_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block1_2_conv[0][0]']
 ization)

 conv2_block1_2_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block1_2_bn[0][0]']
 n)

 conv2_block1_0_conv (Conv2D)   (None, 16, 16, 256)  16640       ['pool1_pool[0][0]']

 conv2_block1_3_conv (Conv2D)   (None, 16, 16, 256)  16640       ['conv2_block1_2_relu[0][0]']

 conv2_block1_0_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv2_block1_0_conv[0][0]']
 ization)

 conv2_block1_3_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv2_block1_3_conv[0][0]']
 ization)

 conv2_block1_add (Add)         (None, 16, 16, 256)  0           ['conv2_block1_0_bn[0][0]',
                                                                  'conv2_block1_3_bn[0][0]']

 conv2_block1_out (Activation)  (None, 16, 16, 256)  0           ['conv2_block1_add[0][0]']

 conv2_block2_1_conv (Conv2D)   (None, 16, 16, 64)   16448       ['conv2_block1_out[0][0]']

 conv2_block2_1_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block2_1_conv[0][0]']
 ization)

 conv2_block2_1_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block2_1_bn[0][0]']
 n)

 conv2_block2_2_conv (Conv2D)   (None, 16, 16, 64)   36928       ['conv2_block2_1_relu[0][0]']

 conv2_block2_2_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block2_2_conv[0][0]']
 ization)

 conv2_block2_2_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block2_2_bn[0][0]']
 n)

 conv2_block2_3_conv (Conv2D)   (None, 16, 16, 256)  16640       ['conv2_block2_2_relu[0][0]']

 conv2_block2_3_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv2_block2_3_conv[0][0]']
 ization)

 conv2_block2_add (Add)         (None, 16, 16, 256)  0           ['conv2_block1_out[0][0]',
                                                                  'conv2_block2_3_bn[0][0]']

 conv2_block2_out (Activation)  (None, 16, 16, 256)  0           ['conv2_block2_add[0][0]']

 conv2_block3_1_conv (Conv2D)   (None, 16, 16, 64)   16448       ['conv2_block2_out[0][0]']

 conv2_block3_1_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block3_1_conv[0][0]']
 ization)

 conv2_block3_1_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block3_1_bn[0][0]']
 n)

 conv2_block3_2_conv (Conv2D)   (None, 16, 16, 64)   36928       ['conv2_block3_1_relu[0][0]']

 conv2_block3_2_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block3_2_conv[0][0]']
 ization)

 conv2_block3_2_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block3_2_bn[0][0]']
 n)

 conv2_block3_3_conv (Conv2D)   (None, 16, 16, 256)  16640       ['conv2_block3_2_relu[0][0]']

 conv2_block3_3_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv2_block3_3_conv[0][0]']
 ization)

 conv2_block3_add (Add)         (None, 16, 16, 256)  0           ['conv2_block2_out[0][0]',
                                                                  'conv2_block3_3_bn[0][0]']

 conv2_block3_out (Activation)  (None, 16, 16, 256)  0           ['conv2_block3_add[0][0]']

 conv3_block1_1_conv (Conv2D)   (None, 8, 8, 128)    32896       ['conv2_block3_out[0][0]']

 conv3_block1_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block1_1_conv[0][0]']
 ization)

 conv3_block1_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block1_1_bn[0][0]']
 n)

 conv3_block1_2_conv (Conv2D)   (None, 8, 8, 128)    147584      ['conv3_block1_1_relu[0][0]']

 conv3_block1_2_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block1_2_conv[0][0]']
 ization)

 conv3_block1_2_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block1_2_bn[0][0]']
 n)

 conv3_block1_0_conv (Conv2D)   (None, 8, 8, 512)    131584      ['conv2_block3_out[0][0]']

 conv3_block1_3_conv (Conv2D)   (None, 8, 8, 512)    66048       ['conv3_block1_2_relu[0][0]']

 conv3_block1_0_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv3_block1_0_conv[0][0]']
 ization)

 conv3_block1_3_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv3_block1_3_conv[0][0]']
 ization)

 conv3_block1_add (Add)         (None, 8, 8, 512)    0           ['conv3_block1_0_bn[0][0]',
                                                                  'conv3_block1_3_bn[0][0]']

 conv3_block1_out (Activation)  (None, 8, 8, 512)    0           ['conv3_block1_add[0][0]']

 conv3_block2_1_conv (Conv2D)   (None, 8, 8, 128)    65664       ['conv3_block1_out[0][0]']

 conv3_block2_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block2_1_conv[0][0]']
 ization)

 conv3_block2_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block2_1_bn[0][0]']
 n)

 conv3_block2_2_conv (Conv2D)   (None, 8, 8, 128)    147584      ['conv3_block2_1_relu[0][0]']

 conv3_block2_2_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block2_2_conv[0][0]']
 ization)

 conv3_block2_2_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block2_2_bn[0][0]']
 n)

 conv3_block2_3_conv (Conv2D)   (None, 8, 8, 512)    66048       ['conv3_block2_2_relu[0][0]']

 conv3_block2_3_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv3_block2_3_conv[0][0]']
 ization)

 conv3_block2_add (Add)         (None, 8, 8, 512)    0           ['conv3_block1_out[0][0]',
                                                                  'conv3_block2_3_bn[0][0]']

 conv3_block2_out (Activation)  (None, 8, 8, 512)    0           ['conv3_block2_add[0][0]']

 conv3_block3_1_conv (Conv2D)   (None, 8, 8, 128)    65664       ['conv3_block2_out[0][0]']

 conv3_block3_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block3_1_conv[0][0]']
 ization)

 conv3_block3_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block3_1_bn[0][0]']
 n)

 conv3_block3_2_conv (Conv2D)   (None, 8, 8, 128)    147584      ['conv3_block3_1_relu[0][0]']

 conv3_block3_2_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block3_2_conv[0][0]']
 ization)

 conv3_block3_2_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block3_2_bn[0][0]']
 n)

 conv3_block3_3_conv (Conv2D)   (None, 8, 8, 512)    66048       ['conv3_block3_2_relu[0][0]']

 conv3_block3_3_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv3_block3_3_conv[0][0]']
 ization)

 conv3_block3_add (Add)         (None, 8, 8, 512)    0           ['conv3_block2_out[0][0]',
                                                                  'conv3_block3_3_bn[0][0]']

 conv3_block3_out (Activation)  (None, 8, 8, 512)    0           ['conv3_block3_add[0][0]']

 conv3_block4_1_conv (Conv2D)   (None, 8, 8, 128)    65664       ['conv3_block3_out[0][0]']

 conv3_block4_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block4_1_conv[0][0]']
 ization)

 conv3_block4_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block4_1_bn[0][0]']
 n)

 conv3_block4_2_conv (Conv2D)   (None, 8, 8, 128)    147584      ['conv3_block4_1_relu[0][0]']

 conv3_block4_2_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block4_2_conv[0][0]']
 ization)

 conv3_block4_2_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block4_2_bn[0][0]']
 n)

 conv3_block4_3_conv (Conv2D)   (None, 8, 8, 512)    66048       ['conv3_block4_2_relu[0][0]']

 conv3_block4_3_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv3_block4_3_conv[0][0]']
 ization)

 conv3_block4_add (Add)         (None, 8, 8, 512)    0           ['conv3_block3_out[0][0]',
                                                                  'conv3_block4_3_bn[0][0]']

 conv3_block4_out (Activation)  (None, 8, 8, 512)    0           ['conv3_block4_add[0][0]']

 conv4_block1_1_conv (Conv2D)   (None, 4, 4, 256)    131328      ['conv3_block4_out[0][0]']

 conv4_block1_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block1_1_conv[0][0]']
 ization)

 conv4_block1_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block1_1_bn[0][0]']
 n)

 conv4_block1_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block1_1_relu[0][0]']

 conv4_block1_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block1_2_conv[0][0]']
 ization)

 conv4_block1_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block1_2_bn[0][0]']
 n)

 conv4_block1_0_conv (Conv2D)   (None, 4, 4, 1024)   525312      ['conv3_block4_out[0][0]']

 conv4_block1_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block1_2_relu[0][0]']

 conv4_block1_0_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block1_0_conv[0][0]']
 ization)

 conv4_block1_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block1_3_conv[0][0]']
 ization)

 conv4_block1_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block1_0_bn[0][0]',
                                                                  'conv4_block1_3_bn[0][0]']

 conv4_block1_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block1_add[0][0]']

 conv4_block2_1_conv (Conv2D)   (None, 4, 4, 256)    262400      ['conv4_block1_out[0][0]']

 conv4_block2_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block2_1_conv[0][0]']
 ization)

 conv4_block2_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block2_1_bn[0][0]']
 n)

 conv4_block2_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block2_1_relu[0][0]']

 conv4_block2_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block2_2_conv[0][0]']
 ization)

 conv4_block2_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block2_2_bn[0][0]']
 n)

 conv4_block2_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block2_2_relu[0][0]']

 conv4_block2_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block2_3_conv[0][0]']
 ization)

 conv4_block2_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block1_out[0][0]',
                                                                  'conv4_block2_3_bn[0][0]']

 conv4_block2_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block2_add[0][0]']

 conv4_block3_1_conv (Conv2D)   (None, 4, 4, 256)    262400      ['conv4_block2_out[0][0]']

 conv4_block3_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block3_1_conv[0][0]']
 ization)

 conv4_block3_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block3_1_bn[0][0]']
 n)

 conv4_block3_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block3_1_relu[0][0]']

 conv4_block3_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block3_2_conv[0][0]']
 ization)

 conv4_block3_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block3_2_bn[0][0]']
 n)

 conv4_block3_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block3_2_relu[0][0]']

 conv4_block3_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block3_3_conv[0][0]']
 ization)

 conv4_block3_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block2_out[0][0]',
                                                                  'conv4_block3_3_bn[0][0]']

 conv4_block3_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block3_add[0][0]']

 conv4_block4_1_conv (Conv2D)   (None, 4, 4, 256)    262400      ['conv4_block3_out[0][0]']

 conv4_block4_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block4_1_conv[0][0]']
 ization)

 conv4_block4_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block4_1_bn[0][0]']
 n)

 conv4_block4_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block4_1_relu[0][0]']

 conv4_block4_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block4_2_conv[0][0]']
 ization)

 conv4_block4_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block4_2_bn[0][0]']
 n)

 conv4_block4_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block4_2_relu[0][0]']

 conv4_block4_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block4_3_conv[0][0]']
 ization)

 conv4_block4_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block3_out[0][0]',
                                                                  'conv4_block4_3_bn[0][0]']

 conv4_block4_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block4_add[0][0]']

 conv4_block5_1_conv (Conv2D)   (None, 4, 4, 256)    262400      ['conv4_block4_out[0][0]']

 conv4_block5_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block5_1_conv[0][0]']
 ization)

 conv4_block5_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block5_1_bn[0][0]']
 n)

 conv4_block5_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block5_1_relu[0][0]']

 conv4_block5_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block5_2_conv[0][0]']
 ization)

 conv4_block5_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block5_2_bn[0][0]']
 n)

 conv4_block5_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block5_2_relu[0][0]']

 conv4_block5_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block5_3_conv[0][0]']
 ization)

 conv4_block5_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block4_out[0][0]',
                                                                  'conv4_block5_3_bn[0][0]']

 conv4_block5_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block5_add[0][0]']

 conv4_block6_1_conv (Conv2D)   (None, 4, 4, 256)    262400      ['conv4_block5_out[0][0]']

 conv4_block6_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block6_1_conv[0][0]']
 ization)

 conv4_block6_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block6_1_bn[0][0]']
 n)

 conv4_block6_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block6_1_relu[0][0]']

 conv4_block6_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block6_2_conv[0][0]']
 ization)

 conv4_block6_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block6_2_bn[0][0]']
 n)

 conv4_block6_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block6_2_relu[0][0]']

 conv4_block6_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block6_3_conv[0][0]']
 ization)

 conv4_block6_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block5_out[0][0]',
                                                                  'conv4_block6_3_bn[0][0]']

 conv4_block6_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block6_add[0][0]']

 conv5_block1_1_conv (Conv2D)   (None, 2, 2, 512)    524800      ['conv4_block6_out[0][0]']

 conv5_block1_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block1_1_conv[0][0]']
 ization)

 conv5_block1_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block1_1_bn[0][0]']
 n)

 conv5_block1_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block1_1_relu[0][0]']

 conv5_block1_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block1_2_conv[0][0]']
 ization)

 conv5_block1_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block1_2_bn[0][0]']
 n)

 conv5_block1_0_conv (Conv2D)   (None, 2, 2, 2048)   2099200     ['conv4_block6_out[0][0]']

 conv5_block1_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block1_2_relu[0][0]']

 conv5_block1_0_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block1_0_conv[0][0]']
 ization)

 conv5_block1_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block1_3_conv[0][0]']
 ization)

 conv5_block1_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block1_0_bn[0][0]',
                                                                  'conv5_block1_3_bn[0][0]']

 conv5_block1_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block1_add[0][0]']

 conv5_block2_1_conv (Conv2D)   (None, 2, 2, 512)    1049088     ['conv5_block1_out[0][0]']

 conv5_block2_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block2_1_conv[0][0]']
 ization)

 conv5_block2_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block2_1_bn[0][0]']
 n)

 conv5_block2_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block2_1_relu[0][0]']

 conv5_block2_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block2_2_conv[0][0]']
 ization)

 conv5_block2_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block2_2_bn[0][0]']
 n)

 conv5_block2_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block2_2_relu[0][0]']

 conv5_block2_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block2_3_conv[0][0]']
 ization)

 conv5_block2_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block1_out[0][0]',
                                                                  'conv5_block2_3_bn[0][0]']

 conv5_block2_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block2_add[0][0]']

 conv5_block3_1_conv (Conv2D)   (None, 2, 2, 512)    1049088     ['conv5_block2_out[0][0]']

 conv5_block3_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block3_1_conv[0][0]']
 ization)

 conv5_block3_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block3_1_bn[0][0]']
 n)

 conv5_block3_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block3_1_relu[0][0]']

 conv5_block3_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block3_2_conv[0][0]']
 ization)

 conv5_block3_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block3_2_bn[0][0]']
 n)

 conv5_block3_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block3_2_relu[0][0]']

 conv5_block3_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block3_3_conv[0][0]']
 ization)

 conv5_block3_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block2_out[0][0]',
                                                                  'conv5_block3_3_bn[0][0]']

 conv5_block3_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block3_add[0][0]']

 avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']
 2D)

==================================================================================================
Total params: 23,587,712
Trainable params: 0
Non-trainable params: 23,587,712
__________________________________________________________________________________________________
Base model: None
Model: "model_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 input_4 (InputLayer)        [(None, 64, 64, 3)]       0

 data_augmentation (Sequenti  (None, 64, 64, 3)        0
 al)

 tf.__operators__.getitem_1   (None, 64, 64, 3)        0
 (SlicingOpLambda)

 tf.nn.bias_add_1 (TFOpLambd  (None, 64, 64, 3)        0
 a)

 resnet50 (Functional)       (None, 2048)              23587712

 flatten_1 (Flatten)         (None, 2048)              0

 dense_2 (Dense)             (None, 128)               262272

 dropout_1 (Dropout)         (None, 128)               0

 dense_3 (Dense)             (None, 10)                1290

=================================================================
Total params: 23,851,274
Trainable params: 263,562
Non-trainable params: 23,587,712
_________________________________________________________________
Model: None
Epoch 1/25
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input "contrast_factor" of op 'AdjustContrastv2' expected to be loop invariant.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input "contrast_factor" of op 'AdjustContrastv2' expected to be loop invariant.
600/600 [==============================] - 347s 569ms/step - loss: 1.1894 - accuracy: 0.6370 - val_loss: 0.4197 - val_accuracy: 0.8679
Epoch 2/25
600/600 [==============================] - 348s 579ms/step - loss: 0.6002 - accuracy: 0.8085 - val_loss: 0.3503 - val_accuracy: 0.8904
Epoch 3/25
600/600 [==============================] - 346s 577ms/step - loss: 0.4909 - accuracy: 0.8422 - val_loss: 0.3026 - val_accuracy: 0.9031
Epoch 4/25
600/600 [==============================] - 345s 576ms/step - loss: 0.4398 - accuracy: 0.8543 - val_loss: 0.2781 - val_accuracy: 0.9125
Epoch 5/25
600/600 [==============================] - 346s 578ms/step - loss: 0.3915 - accuracy: 0.8724 - val_loss: 0.2736 - val_accuracy: 0.9135
Epoch 6/25
600/600 [==============================] - 347s 579ms/step - loss: 0.3748 - accuracy: 0.8755 - val_loss: 0.2638 - val_accuracy: 0.9146
Epoch 7/25
600/600 [==============================] - 346s 576ms/step - loss: 0.3595 - accuracy: 0.8813 - val_loss: 0.2378 - val_accuracy: 0.9190
Epoch 8/25
600/600 [==============================] - 347s 578ms/step - loss: 0.3335 - accuracy: 0.8897 - val_loss: 0.2356 - val_accuracy: 0.9210
Epoch 9/25
600/600 [==============================] - 346s 577ms/step - loss: 0.3222 - accuracy: 0.8920 - val_loss: 0.2332 - val_accuracy: 0.9210
Epoch 10/25
600/600 [==============================] - 345s 575ms/step - loss: 0.3134 - accuracy: 0.8957 - val_loss: 0.2318 - val_accuracy: 0.9225
Epoch 11/25
600/600 [==============================] - 346s 576ms/step - loss: 0.3045 - accuracy: 0.8972 - val_loss: 0.2252 - val_accuracy: 0.9262
Epoch 12/25
600/600 [==============================] - 346s 577ms/step - loss: 0.2900 - accuracy: 0.9026 - val_loss: 0.2156 - val_accuracy: 0.9317
Epoch 13/25
600/600 [==============================] - 345s 575ms/step - loss: 0.2874 - accuracy: 0.9043 - val_loss: 0.2155 - val_accuracy: 0.9292
Epoch 14/25
600/600 [==============================] - 347s 578ms/step - loss: 0.2833 - accuracy: 0.9031 - val_loss: 0.2154 - val_accuracy: 0.9258
Epoch 15/25
600/600 [==============================] - 346s 577ms/step - loss: 0.2689 - accuracy: 0.9089 - val_loss: 0.2114 - val_accuracy: 0.9292
Epoch 16/25
600/600 [==============================] - 347s 578ms/step - loss: 0.2655 - accuracy: 0.9120 - val_loss: 0.2097 - val_accuracy: 0.9325
Epoch 17/25
600/600 [==============================] - 347s 578ms/step - loss: 0.2567 - accuracy: 0.9126 - val_loss: 0.2118 - val_accuracy: 0.9300
Epoch 18/25
600/600 [==============================] - 346s 577ms/step - loss: 0.2562 - accuracy: 0.9161 - val_loss: 0.2060 - val_accuracy: 0.9335
Epoch 19/25
600/600 [==============================] - 344s 574ms/step - loss: 0.2537 - accuracy: 0.9137 - val_loss: 0.2099 - val_accuracy: 0.9300
Epoch 20/25
600/600 [==============================] - 346s 576ms/step - loss: 0.2433 - accuracy: 0.9183 - val_loss: 0.2124 - val_accuracy: 0.9302
Epoch 21/25
600/600 [==============================] - 345s 575ms/step - loss: 0.2503 - accuracy: 0.9168 - val_loss: 0.2045 - val_accuracy: 0.9312
Epoch 22/25
600/600 [==============================] - 348s 580ms/step - loss: 0.2392 - accuracy: 0.9211 - val_loss: 0.2028 - val_accuracy: 0.9312
Epoch 23/25
600/600 [==============================] - 348s 579ms/step - loss: 0.2338 - accuracy: 0.9221 - val_loss: 0.2052 - val_accuracy: 0.9302
Epoch 24/25
600/600 [==============================] - 346s 577ms/step - loss: 0.2279 - accuracy: 0.9234 - val_loss: 0.2023 - val_accuracy: 0.9321
Epoch 25/25
600/600 [==============================] - 346s 576ms/step - loss: 0.2277 - accuracy: 0.9224 - val_loss: 0.2027 - val_accuracy: 0.9312
Model: "model_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 input_4 (InputLayer)        [(None, 64, 64, 3)]       0

 data_augmentation (Sequenti  (None, 64, 64, 3)        0
 al)

 tf.__operators__.getitem_1   (None, 64, 64, 3)        0
 (SlicingOpLambda)

 tf.nn.bias_add_1 (TFOpLambd  (None, 64, 64, 3)        0
 a)

 resnet50 (Functional)       (None, 2048)              23587712

 flatten_1 (Flatten)         (None, 2048)              0

 dense_2 (Dense)             (None, 128)               262272

 dropout_1 (Dropout)         (None, 128)               0

 dense_3 (Dense)             (None, 10)                1290

=================================================================
Total params: 23,851,274
Trainable params: 4,729,226
Non-trainable params: 19,122,048
_________________________________________________________________
ResNet50 Model: None
Epoch 1/50
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input "contrast_factor" of op 'AdjustContrastv2' expected to be loop invariant.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input "contrast_factor" of op 'AdjustContrastv2' expected to be loop invariant.
600/600 [==============================] - 354s 581ms/step - loss: 0.2351 - accuracy: 0.9211 - val_loss: 0.1868 - val_accuracy: 0.9344
Epoch 2/50
600/600 [==============================] - 348s 580ms/step - loss: 0.2137 - accuracy: 0.9270 - val_loss: 0.1994 - val_accuracy: 0.9327
Epoch 3/50
600/600 [==============================] - 346s 577ms/step - loss: 0.2049 - accuracy: 0.9265 - val_loss: 0.1889 - val_accuracy: 0.9383
Epoch 4/50
600/600 [==============================] - 346s 577ms/step - loss: 0.2024 - accuracy: 0.9307 - val_loss: 0.1791 - val_accuracy: 0.9388
Epoch 5/50
600/600 [==============================] - 346s 577ms/step - loss: 0.1920 - accuracy: 0.9347 - val_loss: 0.1833 - val_accuracy: 0.9388
Epoch 6/50
600/600 [==============================] - 347s 579ms/step - loss: 0.1844 - accuracy: 0.9385 - val_loss: 0.1790 - val_accuracy: 0.9427
Epoch 7/50
600/600 [==============================] - 347s 579ms/step - loss: 0.1815 - accuracy: 0.9384 - val_loss: 0.1882 - val_accuracy: 0.9371
Epoch 8/50
600/600 [==============================] - 345s 576ms/step - loss: 0.1743 - accuracy: 0.9401 - val_loss: 0.1754 - val_accuracy: 0.9444
Epoch 9/50
600/600 [==============================] - 348s 579ms/step - loss: 0.1611 - accuracy: 0.9484 - val_loss: 0.1803 - val_accuracy: 0.9433
Epoch 10/50
600/600 [==============================] - 346s 577ms/step - loss: 0.1554 - accuracy: 0.9487 - val_loss: 0.1800 - val_accuracy: 0.9419
Epoch 11/50
600/600 [==============================] - 346s 577ms/step - loss: 0.1492 - accuracy: 0.9504 - val_loss: 0.1955 - val_accuracy: 0.9398
Epoch 12/50
600/600 [==============================] - 348s 579ms/step - loss: 0.1407 - accuracy: 0.9539 - val_loss: 0.1811 - val_accuracy: 0.9417
Epoch 13/50
600/600 [==============================] - 347s 578ms/step - loss: 0.1391 - accuracy: 0.9540 - val_loss: 0.1995 - val_accuracy: 0.9425
Epoch 14/50
600/600 [==============================] - 345s 576ms/step - loss: 0.1303 - accuracy: 0.9551 - val_loss: 0.2047 - val_accuracy: 0.9413
Epoch 15/50
600/600 [==============================] - 347s 578ms/step - loss: 0.1188 - accuracy: 0.9598 - val_loss: 0.2142 - val_accuracy: 0.9371
Epoch 16/50
600/600 [==============================] - 346s 577ms/step - loss: 0.1147 - accuracy: 0.9608 - val_loss: 0.1984 - val_accuracy: 0.9444
Epoch 17/50
600/600 [==============================] - 347s 578ms/step - loss: 0.1103 - accuracy: 0.9633 - val_loss: 0.2086 - val_accuracy: 0.9431
Epoch 18/50
600/600 [==============================] - 346s 576ms/step - loss: 0.1090 - accuracy: 0.9638 - val_loss: 0.2046 - val_accuracy: 0.9410
Epoch 19/50
600/600 [==============================] - 346s 577ms/step - loss: 0.0965 - accuracy: 0.9680 - val_loss: 0.2045 - val_accuracy: 0.9425
Epoch 20/50
600/600 [==============================] - 348s 579ms/step - loss: 0.0889 - accuracy: 0.9703 - val_loss: 0.2343 - val_accuracy: 0.9379
Epoch 21/50
600/600 [==============================] - 347s 579ms/step - loss: 0.0880 - accuracy: 0.9698 - val_loss: 0.2287 - val_accuracy: 0.9365
Epoch 22/50
600/600 [==============================] - 348s 580ms/step - loss: 0.0857 - accuracy: 0.9710 - val_loss: 0.2312 - val_accuracy: 0.9381
Epoch 23/50
600/600 [==============================] - 347s 578ms/step - loss: 0.0857 - accuracy: 0.9712 - val_loss: 0.2582 - val_accuracy: 0.9346
Epoch 24/50
600/600 [==============================] - 347s 579ms/step - loss: 0.0774 - accuracy: 0.9745 - val_loss: 0.2462 - val_accuracy: 0.9394
Epoch 25/50
600/600 [==============================] - 343s 572ms/step - loss: 0.0806 - accuracy: 0.9733 - val_loss: 0.2494 - val_accuracy: 0.9373
Epoch 26/50
600/600 [==============================] - 347s 579ms/step - loss: 0.0725 - accuracy: 0.9764 - val_loss: 0.2342 - val_accuracy: 0.9435
Epoch 27/50
600/600 [==============================] - 348s 580ms/step - loss: 0.0707 - accuracy: 0.9764 - val_loss: 0.2511 - val_accuracy: 0.9392
Epoch 28/50
600/600 [==============================] - 348s 580ms/step - loss: 0.0685 - accuracy: 0.9764 - val_loss: 0.2674 - val_accuracy: 0.9377
Epoch 29/50
600/600 [==============================] - 346s 577ms/step - loss: 0.0695 - accuracy: 0.9767 - val_loss: 0.2342 - val_accuracy: 0.9431
Epoch 30/50
600/600 [==============================] - 347s 578ms/step - loss: 0.0630 - accuracy: 0.9795 - val_loss: 0.3182 - val_accuracy: 0.9325
Epoch 31/50
600/600 [==============================] - 347s 579ms/step - loss: 0.0672 - accuracy: 0.9786 - val_loss: 0.2599 - val_accuracy: 0.9383
Epoch 32/50
600/600 [==============================] - 347s 578ms/step - loss: 0.0615 - accuracy: 0.9801 - val_loss: 0.2772 - val_accuracy: 0.9379
Epoch 33/50
600/600 [==============================] - 347s 579ms/step - loss: 0.0626 - accuracy: 0.9797 - val_loss: 0.2384 - val_accuracy: 0.9419
Epoch 34/50
600/600 [==============================] - 348s 580ms/step - loss: 0.0621 - accuracy: 0.9794 - val_loss: 0.2757 - val_accuracy: 0.9373
Epoch 35/50
600/600 [==============================] - 349s 582ms/step - loss: 0.0517 - accuracy: 0.9825 - val_loss: 0.3347 - val_accuracy: 0.9350
Epoch 36/50
600/600 [==============================] - 348s 580ms/step - loss: 0.0568 - accuracy: 0.9820 - val_loss: 0.2686 - val_accuracy: 0.9458
Epoch 37/50
600/600 [==============================] - 347s 578ms/step - loss: 0.0528 - accuracy: 0.9825 - val_loss: 0.2414 - val_accuracy: 0.9433
Epoch 38/50
600/600 [==============================] - 348s 580ms/step - loss: 0.0541 - accuracy: 0.9814 - val_loss: 0.2627 - val_accuracy: 0.9433
Epoch 39/50
600/600 [==============================] - 348s 580ms/step - loss: 0.0545 - accuracy: 0.9823 - val_loss: 0.2902 - val_accuracy: 0.9408
Epoch 40/50
600/600 [==============================] - 347s 579ms/step - loss: 0.0486 - accuracy: 0.9841 - val_loss: 0.2694 - val_accuracy: 0.9417
Epoch 41/50
600/600 [==============================] - 348s 580ms/step - loss: 0.0468 - accuracy: 0.9851 - val_loss: 0.2999 - val_accuracy: 0.9390
Epoch 42/50
600/600 [==============================] - 349s 582ms/step - loss: 0.0451 - accuracy: 0.9856 - val_loss: 0.3017 - val_accuracy: 0.9398
Epoch 43/50
600/600 [==============================] - 349s 582ms/step - loss: 0.0472 - accuracy: 0.9853 - val_loss: 0.3081 - val_accuracy: 0.9383
Epoch 44/50
600/600 [==============================] - 348s 580ms/step - loss: 0.0465 - accuracy: 0.9851 - val_loss: 0.2891 - val_accuracy: 0.9415
Epoch 45/50
600/600 [==============================] - 347s 579ms/step - loss: 0.0488 - accuracy: 0.9847 - val_loss: 0.3029 - val_accuracy: 0.9346
Epoch 46/50
600/600 [==============================] - 348s 580ms/step - loss: 0.0436 - accuracy: 0.9869 - val_loss: 0.2662 - val_accuracy: 0.9446
Epoch 47/50
600/600 [==============================] - 348s 580ms/step - loss: 0.0418 - accuracy: 0.9866 - val_loss: 0.2754 - val_accuracy: 0.9417
Epoch 48/50
600/600 [==============================] - 347s 579ms/step - loss: 0.0414 - accuracy: 0.9866 - val_loss: 0.3140 - val_accuracy: 0.9429
Epoch 49/50
600/600 [==============================] - 346s 577ms/step - loss: 0.0449 - accuracy: 0.9867 - val_loss: 0.3171 - val_accuracy: 0.9383
Epoch 50/50
600/600 [==============================] - 348s 580ms/step - loss: 0.0400 - accuracy: 0.9872 - val_loss: 0.3166 - val_accuracy: 0.9367
=======================================resnet50_phase_B_2==============================================
Model: "resnet50"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to
==================================================================================================
 input_5 (InputLayer)           [(None, 64, 64, 3)]  0           []

 conv1_pad (ZeroPadding2D)      (None, 70, 70, 3)    0           ['input_5[0][0]']

 conv1_conv (Conv2D)            (None, 32, 32, 64)   9472        ['conv1_pad[0][0]']

 conv1_bn (BatchNormalization)  (None, 32, 32, 64)   256         ['conv1_conv[0][0]']

 conv1_relu (Activation)        (None, 32, 32, 64)   0           ['conv1_bn[0][0]']

 pool1_pad (ZeroPadding2D)      (None, 34, 34, 64)   0           ['conv1_relu[0][0]']

 pool1_pool (MaxPooling2D)      (None, 16, 16, 64)   0           ['pool1_pad[0][0]']

 conv2_block1_1_conv (Conv2D)   (None, 16, 16, 64)   4160        ['pool1_pool[0][0]']

 conv2_block1_1_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block1_1_conv[0][0]']
 ization)

 conv2_block1_1_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block1_1_bn[0][0]']
 n)

 conv2_block1_2_conv (Conv2D)   (None, 16, 16, 64)   36928       ['conv2_block1_1_relu[0][0]']

 conv2_block1_2_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block1_2_conv[0][0]']
 ization)

 conv2_block1_2_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block1_2_bn[0][0]']
 n)

 conv2_block1_0_conv (Conv2D)   (None, 16, 16, 256)  16640       ['pool1_pool[0][0]']

 conv2_block1_3_conv (Conv2D)   (None, 16, 16, 256)  16640       ['conv2_block1_2_relu[0][0]']

 conv2_block1_0_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv2_block1_0_conv[0][0]']
 ization)

 conv2_block1_3_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv2_block1_3_conv[0][0]']
 ization)

 conv2_block1_add (Add)         (None, 16, 16, 256)  0           ['conv2_block1_0_bn[0][0]',
                                                                  'conv2_block1_3_bn[0][0]']

 conv2_block1_out (Activation)  (None, 16, 16, 256)  0           ['conv2_block1_add[0][0]']

 conv2_block2_1_conv (Conv2D)   (None, 16, 16, 64)   16448       ['conv2_block1_out[0][0]']

 conv2_block2_1_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block2_1_conv[0][0]']
 ization)

 conv2_block2_1_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block2_1_bn[0][0]']
 n)

 conv2_block2_2_conv (Conv2D)   (None, 16, 16, 64)   36928       ['conv2_block2_1_relu[0][0]']

 conv2_block2_2_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block2_2_conv[0][0]']
 ization)

 conv2_block2_2_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block2_2_bn[0][0]']
 n)

 conv2_block2_3_conv (Conv2D)   (None, 16, 16, 256)  16640       ['conv2_block2_2_relu[0][0]']

 conv2_block2_3_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv2_block2_3_conv[0][0]']
 ization)

 conv2_block2_add (Add)         (None, 16, 16, 256)  0           ['conv2_block1_out[0][0]',
                                                                  'conv2_block2_3_bn[0][0]']

 conv2_block2_out (Activation)  (None, 16, 16, 256)  0           ['conv2_block2_add[0][0]']

 conv2_block3_1_conv (Conv2D)   (None, 16, 16, 64)   16448       ['conv2_block2_out[0][0]']

 conv2_block3_1_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block3_1_conv[0][0]']
 ization)

 conv2_block3_1_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block3_1_bn[0][0]']
 n)

 conv2_block3_2_conv (Conv2D)   (None, 16, 16, 64)   36928       ['conv2_block3_1_relu[0][0]']

 conv2_block3_2_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block3_2_conv[0][0]']
 ization)

 conv2_block3_2_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block3_2_bn[0][0]']
 n)

 conv2_block3_3_conv (Conv2D)   (None, 16, 16, 256)  16640       ['conv2_block3_2_relu[0][0]']

 conv2_block3_3_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv2_block3_3_conv[0][0]']
 ization)

 conv2_block3_add (Add)         (None, 16, 16, 256)  0           ['conv2_block2_out[0][0]',
                                                                  'conv2_block3_3_bn[0][0]']

 conv2_block3_out (Activation)  (None, 16, 16, 256)  0           ['conv2_block3_add[0][0]']

 conv3_block1_1_conv (Conv2D)   (None, 8, 8, 128)    32896       ['conv2_block3_out[0][0]']

 conv3_block1_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block1_1_conv[0][0]']
 ization)

 conv3_block1_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block1_1_bn[0][0]']
 n)

 conv3_block1_2_conv (Conv2D)   (None, 8, 8, 128)    147584      ['conv3_block1_1_relu[0][0]']

 conv3_block1_2_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block1_2_conv[0][0]']
 ization)

 conv3_block1_2_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block1_2_bn[0][0]']
 n)

 conv3_block1_0_conv (Conv2D)   (None, 8, 8, 512)    131584      ['conv2_block3_out[0][0]']

 conv3_block1_3_conv (Conv2D)   (None, 8, 8, 512)    66048       ['conv3_block1_2_relu[0][0]']

 conv3_block1_0_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv3_block1_0_conv[0][0]']
 ization)

 conv3_block1_3_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv3_block1_3_conv[0][0]']
 ization)

 conv3_block1_add (Add)         (None, 8, 8, 512)    0           ['conv3_block1_0_bn[0][0]',
                                                                  'conv3_block1_3_bn[0][0]']

 conv3_block1_out (Activation)  (None, 8, 8, 512)    0           ['conv3_block1_add[0][0]']

 conv3_block2_1_conv (Conv2D)   (None, 8, 8, 128)    65664       ['conv3_block1_out[0][0]']

 conv3_block2_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block2_1_conv[0][0]']
 ization)

 conv3_block2_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block2_1_bn[0][0]']
 n)

 conv3_block2_2_conv (Conv2D)   (None, 8, 8, 128)    147584      ['conv3_block2_1_relu[0][0]']

 conv3_block2_2_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block2_2_conv[0][0]']
 ization)

 conv3_block2_2_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block2_2_bn[0][0]']
 n)

 conv3_block2_3_conv (Conv2D)   (None, 8, 8, 512)    66048       ['conv3_block2_2_relu[0][0]']

 conv3_block2_3_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv3_block2_3_conv[0][0]']
 ization)

 conv3_block2_add (Add)         (None, 8, 8, 512)    0           ['conv3_block1_out[0][0]',
                                                                  'conv3_block2_3_bn[0][0]']

 conv3_block2_out (Activation)  (None, 8, 8, 512)    0           ['conv3_block2_add[0][0]']

 conv3_block3_1_conv (Conv2D)   (None, 8, 8, 128)    65664       ['conv3_block2_out[0][0]']

 conv3_block3_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block3_1_conv[0][0]']
 ization)

 conv3_block3_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block3_1_bn[0][0]']
 n)

 conv3_block3_2_conv (Conv2D)   (None, 8, 8, 128)    147584      ['conv3_block3_1_relu[0][0]']

 conv3_block3_2_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block3_2_conv[0][0]']
 ization)

 conv3_block3_2_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block3_2_bn[0][0]']
 n)

 conv3_block3_3_conv (Conv2D)   (None, 8, 8, 512)    66048       ['conv3_block3_2_relu[0][0]']

 conv3_block3_3_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv3_block3_3_conv[0][0]']
 ization)

 conv3_block3_add (Add)         (None, 8, 8, 512)    0           ['conv3_block2_out[0][0]',
                                                                  'conv3_block3_3_bn[0][0]']

 conv3_block3_out (Activation)  (None, 8, 8, 512)    0           ['conv3_block3_add[0][0]']

 conv3_block4_1_conv (Conv2D)   (None, 8, 8, 128)    65664       ['conv3_block3_out[0][0]']

 conv3_block4_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block4_1_conv[0][0]']
 ization)

 conv3_block4_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block4_1_bn[0][0]']
 n)

 conv3_block4_2_conv (Conv2D)   (None, 8, 8, 128)    147584      ['conv3_block4_1_relu[0][0]']

 conv3_block4_2_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block4_2_conv[0][0]']
 ization)

 conv3_block4_2_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block4_2_bn[0][0]']
 n)

 conv3_block4_3_conv (Conv2D)   (None, 8, 8, 512)    66048       ['conv3_block4_2_relu[0][0]']

 conv3_block4_3_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv3_block4_3_conv[0][0]']
 ization)

 conv3_block4_add (Add)         (None, 8, 8, 512)    0           ['conv3_block3_out[0][0]',
                                                                  'conv3_block4_3_bn[0][0]']

 conv3_block4_out (Activation)  (None, 8, 8, 512)    0           ['conv3_block4_add[0][0]']

 conv4_block1_1_conv (Conv2D)   (None, 4, 4, 256)    131328      ['conv3_block4_out[0][0]']

 conv4_block1_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block1_1_conv[0][0]']
 ization)

 conv4_block1_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block1_1_bn[0][0]']
 n)

 conv4_block1_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block1_1_relu[0][0]']

 conv4_block1_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block1_2_conv[0][0]']
 ization)

 conv4_block1_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block1_2_bn[0][0]']
 n)

 conv4_block1_0_conv (Conv2D)   (None, 4, 4, 1024)   525312      ['conv3_block4_out[0][0]']

 conv4_block1_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block1_2_relu[0][0]']

 conv4_block1_0_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block1_0_conv[0][0]']
 ization)

 conv4_block1_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block1_3_conv[0][0]']
 ization)

 conv4_block1_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block1_0_bn[0][0]',
                                                                  'conv4_block1_3_bn[0][0]']

 conv4_block1_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block1_add[0][0]']

 conv4_block2_1_conv (Conv2D)   (None, 4, 4, 256)    262400      ['conv4_block1_out[0][0]']

 conv4_block2_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block2_1_conv[0][0]']
 ization)

 conv4_block2_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block2_1_bn[0][0]']
 n)

 conv4_block2_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block2_1_relu[0][0]']

 conv4_block2_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block2_2_conv[0][0]']
 ization)

 conv4_block2_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block2_2_bn[0][0]']
 n)

 conv4_block2_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block2_2_relu[0][0]']

 conv4_block2_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block2_3_conv[0][0]']
 ization)

 conv4_block2_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block1_out[0][0]',
                                                                  'conv4_block2_3_bn[0][0]']

 conv4_block2_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block2_add[0][0]']

 conv4_block3_1_conv (Conv2D)   (None, 4, 4, 256)    262400      ['conv4_block2_out[0][0]']

 conv4_block3_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block3_1_conv[0][0]']
 ization)

 conv4_block3_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block3_1_bn[0][0]']
 n)

 conv4_block3_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block3_1_relu[0][0]']

 conv4_block3_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block3_2_conv[0][0]']
 ization)

 conv4_block3_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block3_2_bn[0][0]']
 n)

 conv4_block3_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block3_2_relu[0][0]']

 conv4_block3_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block3_3_conv[0][0]']
 ization)

 conv4_block3_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block2_out[0][0]',
                                                                  'conv4_block3_3_bn[0][0]']

 conv4_block3_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block3_add[0][0]']

 conv4_block4_1_conv (Conv2D)   (None, 4, 4, 256)    262400      ['conv4_block3_out[0][0]']

 conv4_block4_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block4_1_conv[0][0]']
 ization)

 conv4_block4_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block4_1_bn[0][0]']
 n)

 conv4_block4_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block4_1_relu[0][0]']

 conv4_block4_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block4_2_conv[0][0]']
 ization)

 conv4_block4_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block4_2_bn[0][0]']
 n)

 conv4_block4_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block4_2_relu[0][0]']

 conv4_block4_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block4_3_conv[0][0]']
 ization)

 conv4_block4_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block3_out[0][0]',
                                                                  'conv4_block4_3_bn[0][0]']

 conv4_block4_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block4_add[0][0]']

 conv4_block5_1_conv (Conv2D)   (None, 4, 4, 256)    262400      ['conv4_block4_out[0][0]']

 conv4_block5_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block5_1_conv[0][0]']
 ization)

 conv4_block5_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block5_1_bn[0][0]']
 n)

 conv4_block5_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block5_1_relu[0][0]']

 conv4_block5_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block5_2_conv[0][0]']
 ization)

 conv4_block5_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block5_2_bn[0][0]']
 n)

 conv4_block5_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block5_2_relu[0][0]']

 conv4_block5_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block5_3_conv[0][0]']
 ization)

 conv4_block5_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block4_out[0][0]',
                                                                  'conv4_block5_3_bn[0][0]']

 conv4_block5_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block5_add[0][0]']

 conv4_block6_1_conv (Conv2D)   (None, 4, 4, 256)    262400      ['conv4_block5_out[0][0]']

 conv4_block6_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block6_1_conv[0][0]']
 ization)

 conv4_block6_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block6_1_bn[0][0]']
 n)

 conv4_block6_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block6_1_relu[0][0]']

 conv4_block6_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block6_2_conv[0][0]']
 ization)

 conv4_block6_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block6_2_bn[0][0]']
 n)

 conv4_block6_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block6_2_relu[0][0]']

 conv4_block6_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block6_3_conv[0][0]']
 ization)

 conv4_block6_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block5_out[0][0]',
                                                                  'conv4_block6_3_bn[0][0]']

 conv4_block6_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block6_add[0][0]']

 conv5_block1_1_conv (Conv2D)   (None, 2, 2, 512)    524800      ['conv4_block6_out[0][0]']

 conv5_block1_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block1_1_conv[0][0]']
 ization)

 conv5_block1_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block1_1_bn[0][0]']
 n)

 conv5_block1_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block1_1_relu[0][0]']

 conv5_block1_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block1_2_conv[0][0]']
 ization)

 conv5_block1_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block1_2_bn[0][0]']
 n)

 conv5_block1_0_conv (Conv2D)   (None, 2, 2, 2048)   2099200     ['conv4_block6_out[0][0]']

 conv5_block1_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block1_2_relu[0][0]']

 conv5_block1_0_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block1_0_conv[0][0]']
 ization)

 conv5_block1_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block1_3_conv[0][0]']
 ization)

 conv5_block1_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block1_0_bn[0][0]',
                                                                  'conv5_block1_3_bn[0][0]']

 conv5_block1_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block1_add[0][0]']

 conv5_block2_1_conv (Conv2D)   (None, 2, 2, 512)    1049088     ['conv5_block1_out[0][0]']

 conv5_block2_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block2_1_conv[0][0]']
 ization)

 conv5_block2_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block2_1_bn[0][0]']
 n)

 conv5_block2_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block2_1_relu[0][0]']

 conv5_block2_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block2_2_conv[0][0]']
 ization)

 conv5_block2_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block2_2_bn[0][0]']
 n)

 conv5_block2_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block2_2_relu[0][0]']

 conv5_block2_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block2_3_conv[0][0]']
 ization)

 conv5_block2_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block1_out[0][0]',
                                                                  'conv5_block2_3_bn[0][0]']

 conv5_block2_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block2_add[0][0]']

 conv5_block3_1_conv (Conv2D)   (None, 2, 2, 512)    1049088     ['conv5_block2_out[0][0]']

 conv5_block3_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block3_1_conv[0][0]']
 ization)

 conv5_block3_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block3_1_bn[0][0]']
 n)

 conv5_block3_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block3_1_relu[0][0]']

 conv5_block3_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block3_2_conv[0][0]']
 ization)

 conv5_block3_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block3_2_bn[0][0]']
 n)

 conv5_block3_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block3_2_relu[0][0]']

 conv5_block3_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block3_3_conv[0][0]']
 ization)

 conv5_block3_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block2_out[0][0]',
                                                                  'conv5_block3_3_bn[0][0]']

 conv5_block3_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block3_add[0][0]']

==================================================================================================
Total params: 23,587,712
Trainable params: 0
Non-trainable params: 23,587,712
__________________________________________________________________________________________________
ResNet50 Base model: None
Model: "model_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 input_6 (InputLayer)        [(None, 64, 64, 3)]       0

 data_augmentation (Sequenti  (None, 64, 64, 3)        0
 al)

 tf.__operators__.getitem_2   (None, 64, 64, 3)        0
 (SlicingOpLambda)

 tf.nn.bias_add_2 (TFOpLambd  (None, 64, 64, 3)        0
 a)

 resnet50 (Functional)       (None, 2, 2, 2048)        23587712

 flatten_2 (Flatten)         (None, 8192)              0

 dense_4 (Dense)             (None, 128)               1048704

 dropout_2 (Dropout)         (None, 128)               0

 dense_5 (Dense)             (None, 10)                1290

=================================================================
Total params: 24,637,706
Trainable params: 1,049,994
Non-trainable params: 23,587,712
_________________________________________________________________
ResNet50 Model: None
Epoch 1/25
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input "contrast_factor" of op 'AdjustContrastv2' expected to be loop invariant.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input "contrast_factor" of op 'AdjustContrastv2' expected to be loop invariant.
600/600 [==============================] - 350s 575ms/step - loss: 0.8257 - accuracy: 0.7444 - val_loss: 0.3335 - val_accuracy: 0.8923
Epoch 2/25
600/600 [==============================] - 343s 572ms/step - loss: 0.4677 - accuracy: 0.8491 - val_loss: 0.2718 - val_accuracy: 0.9077
Epoch 3/25
600/600 [==============================] - 345s 575ms/step - loss: 0.4136 - accuracy: 0.8666 - val_loss: 0.2482 - val_accuracy: 0.9158
Epoch 4/25
600/600 [==============================] - 343s 571ms/step - loss: 0.3532 - accuracy: 0.8845 - val_loss: 0.2254 - val_accuracy: 0.9223
Epoch 5/25
600/600 [==============================] - 343s 572ms/step - loss: 0.3252 - accuracy: 0.8928 - val_loss: 0.2188 - val_accuracy: 0.9269
Epoch 6/25
600/600 [==============================] - 344s 573ms/step - loss: 0.3099 - accuracy: 0.8985 - val_loss: 0.2081 - val_accuracy: 0.9306
Epoch 7/25
600/600 [==============================] - 346s 576ms/step - loss: 0.2939 - accuracy: 0.9060 - val_loss: 0.2096 - val_accuracy: 0.9296
Epoch 8/25
600/600 [==============================] - 345s 575ms/step - loss: 0.2733 - accuracy: 0.9092 - val_loss: 0.2080 - val_accuracy: 0.9302
Epoch 9/25
600/600 [==============================] - 347s 578ms/step - loss: 0.2662 - accuracy: 0.9121 - val_loss: 0.2054 - val_accuracy: 0.9298
Epoch 10/25
600/600 [==============================] - 356s 594ms/step - loss: 0.2563 - accuracy: 0.9154 - val_loss: 0.2110 - val_accuracy: 0.9285
Epoch 11/25
600/600 [==============================] - 356s 594ms/step - loss: 0.2426 - accuracy: 0.9189 - val_loss: 0.2001 - val_accuracy: 0.9331
Epoch 12/25
600/600 [==============================] - 356s 594ms/step - loss: 0.2324 - accuracy: 0.9217 - val_loss: 0.1976 - val_accuracy: 0.9319
Epoch 13/25
600/600 [==============================] - 357s 595ms/step - loss: 0.2283 - accuracy: 0.9219 - val_loss: 0.2066 - val_accuracy: 0.9279
Epoch 14/25
600/600 [==============================] - 355s 592ms/step - loss: 0.2208 - accuracy: 0.9273 - val_loss: 0.1888 - val_accuracy: 0.9383
Epoch 15/25
600/600 [==============================] - 355s 593ms/step - loss: 0.2072 - accuracy: 0.9306 - val_loss: 0.1942 - val_accuracy: 0.9362
Epoch 16/25
600/600 [==============================] - 356s 593ms/step - loss: 0.2116 - accuracy: 0.9289 - val_loss: 0.1869 - val_accuracy: 0.9373
Epoch 17/25
600/600 [==============================] - 354s 591ms/step - loss: 0.2017 - accuracy: 0.9313 - val_loss: 0.1924 - val_accuracy: 0.9342
Epoch 18/25
600/600 [==============================] - 357s 595ms/step - loss: 0.2033 - accuracy: 0.9307 - val_loss: 0.1975 - val_accuracy: 0.9367
Epoch 19/25
600/600 [==============================] - 356s 593ms/step - loss: 0.2017 - accuracy: 0.9312 - val_loss: 0.1932 - val_accuracy: 0.9377
Epoch 20/25
600/600 [==============================] - 355s 592ms/step - loss: 0.1886 - accuracy: 0.9353 - val_loss: 0.1857 - val_accuracy: 0.9408
Epoch 21/25
600/600 [==============================] - 336s 560ms/step - loss: 0.1968 - accuracy: 0.9353 - val_loss: 0.2023 - val_accuracy: 0.9356
Epoch 22/25
600/600 [==============================] - 338s 564ms/step - loss: 0.1877 - accuracy: 0.9369 - val_loss: 0.1935 - val_accuracy: 0.9367
Epoch 23/25
600/600 [==============================] - 337s 562ms/step - loss: 0.1771 - accuracy: 0.9397 - val_loss: 0.1927 - val_accuracy: 0.9375
Epoch 24/25
600/600 [==============================] - 338s 564ms/step - loss: 0.1795 - accuracy: 0.9358 - val_loss: 0.1911 - val_accuracy: 0.9417
Epoch 25/25
600/600 [==============================] - 340s 566ms/step - loss: 0.1763 - accuracy: 0.9401 - val_loss: 0.1838 - val_accuracy: 0.9423
Model: "model_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 input_6 (InputLayer)        [(None, 64, 64, 3)]       0

 data_augmentation (Sequenti  (None, 64, 64, 3)        0
 al)

 tf.__operators__.getitem_2   (None, 64, 64, 3)        0
 (SlicingOpLambda)

 tf.nn.bias_add_2 (TFOpLambd  (None, 64, 64, 3)        0
 a)

 resnet50 (Functional)       (None, 2, 2, 2048)        23587712

 flatten_2 (Flatten)         (None, 8192)              0

 dense_4 (Dense)             (None, 128)               1048704

 dropout_2 (Dropout)         (None, 128)               0

 dense_5 (Dense)             (None, 10)                1290

=================================================================
Total params: 24,637,706
Trainable params: 5,515,658
Non-trainable params: 19,122,048
_________________________________________________________________
ResNet50 Model(unfreeze conv5_block3_1_conv): None
Epoch 1/50
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input "contrast_factor" of op 'AdjustContrastv2' expected to be loop invariant.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input "contrast_factor" of op 'AdjustContrastv2' expected to be loop invariant.
600/600 [==============================] - 350s 573ms/step - loss: 0.1724 - accuracy: 0.9415 - val_loss: 0.1827 - val_accuracy: 0.9444
Epoch 2/50
600/600 [==============================] - 344s 574ms/step - loss: 0.1633 - accuracy: 0.9445 - val_loss: 0.1698 - val_accuracy: 0.9471
Epoch 3/50
600/600 [==============================] - 344s 573ms/step - loss: 0.1520 - accuracy: 0.9477 - val_loss: 0.1641 - val_accuracy: 0.9481
Epoch 4/50
600/600 [==============================] - 342s 571ms/step - loss: 0.1445 - accuracy: 0.9495 - val_loss: 0.1690 - val_accuracy: 0.9473
Epoch 5/50
600/600 [==============================] - 343s 573ms/step - loss: 0.1478 - accuracy: 0.9492 - val_loss: 0.1737 - val_accuracy: 0.9452
Epoch 6/50
600/600 [==============================] - 344s 574ms/step - loss: 0.1353 - accuracy: 0.9529 - val_loss: 0.1700 - val_accuracy: 0.9467
Epoch 7/50
600/600 [==============================] - 343s 571ms/step - loss: 0.1305 - accuracy: 0.9530 - val_loss: 0.1727 - val_accuracy: 0.9463
Epoch 8/50
600/600 [==============================] - 344s 574ms/step - loss: 0.1357 - accuracy: 0.9530 - val_loss: 0.1649 - val_accuracy: 0.9463
Epoch 9/50
600/600 [==============================] - 343s 571ms/step - loss: 0.1302 - accuracy: 0.9547 - val_loss: 0.1709 - val_accuracy: 0.9475
Epoch 10/50
600/600 [==============================] - 343s 573ms/step - loss: 0.1239 - accuracy: 0.9569 - val_loss: 0.1789 - val_accuracy: 0.9435
Epoch 11/50
600/600 [==============================] - 342s 571ms/step - loss: 0.1225 - accuracy: 0.9569 - val_loss: 0.1752 - val_accuracy: 0.9452
Epoch 12/50
600/600 [==============================] - 344s 574ms/step - loss: 0.1177 - accuracy: 0.9591 - val_loss: 0.1713 - val_accuracy: 0.9475
Epoch 13/50
600/600 [==============================] - 343s 572ms/step - loss: 0.1148 - accuracy: 0.9590 - val_loss: 0.1700 - val_accuracy: 0.9465
Epoch 14/50
600/600 [==============================] - 342s 570ms/step - loss: 0.1137 - accuracy: 0.9608 - val_loss: 0.1668 - val_accuracy: 0.9519
Epoch 15/50
600/600 [==============================] - 343s 573ms/step - loss: 0.1106 - accuracy: 0.9613 - val_loss: 0.1747 - val_accuracy: 0.9477
Epoch 16/50
600/600 [==============================] - 344s 574ms/step - loss: 0.1071 - accuracy: 0.9623 - val_loss: 0.1778 - val_accuracy: 0.9469
Epoch 17/50
600/600 [==============================] - 344s 573ms/step - loss: 0.1063 - accuracy: 0.9632 - val_loss: 0.1968 - val_accuracy: 0.9467
Epoch 18/50
600/600 [==============================] - 345s 575ms/step - loss: 0.1000 - accuracy: 0.9644 - val_loss: 0.1861 - val_accuracy: 0.9463
Epoch 19/50
600/600 [==============================] - 343s 572ms/step - loss: 0.0984 - accuracy: 0.9669 - val_loss: 0.1802 - val_accuracy: 0.9467
Epoch 20/50
600/600 [==============================] - 342s 571ms/step - loss: 0.0967 - accuracy: 0.9657 - val_loss: 0.1925 - val_accuracy: 0.9467
Epoch 21/50
600/600 [==============================] - 344s 574ms/step - loss: 0.0943 - accuracy: 0.9677 - val_loss: 0.1829 - val_accuracy: 0.9479
Epoch 22/50
600/600 [==============================] - 343s 571ms/step - loss: 0.0887 - accuracy: 0.9699 - val_loss: 0.1761 - val_accuracy: 0.9500
Epoch 23/50
600/600 [==============================] - 343s 571ms/step - loss: 0.0890 - accuracy: 0.9682 - val_loss: 0.1986 - val_accuracy: 0.9448
Epoch 24/50
600/600 [==============================] - 343s 572ms/step - loss: 0.0889 - accuracy: 0.9684 - val_loss: 0.2210 - val_accuracy: 0.9448
Epoch 25/50
600/600 [==============================] - 344s 574ms/step - loss: 0.0851 - accuracy: 0.9702 - val_loss: 0.1846 - val_accuracy: 0.9490
Epoch 26/50
600/600 [==============================] - 342s 570ms/step - loss: 0.0811 - accuracy: 0.9716 - val_loss: 0.1936 - val_accuracy: 0.9471
Epoch 27/50
600/600 [==============================] - 343s 572ms/step - loss: 0.0836 - accuracy: 0.9719 - val_loss: 0.1824 - val_accuracy: 0.9515
Epoch 28/50
600/600 [==============================] - 345s 574ms/step - loss: 0.0799 - accuracy: 0.9729 - val_loss: 0.2097 - val_accuracy: 0.9454
Epoch 29/50
600/600 [==============================] - 342s 570ms/step - loss: 0.0777 - accuracy: 0.9730 - val_loss: 0.1949 - val_accuracy: 0.9463
Epoch 30/50
600/600 [==============================] - 343s 572ms/step - loss: 0.0759 - accuracy: 0.9741 - val_loss: 0.1991 - val_accuracy: 0.9494
Epoch 31/50
600/600 [==============================] - 344s 573ms/step - loss: 0.0723 - accuracy: 0.9755 - val_loss: 0.2127 - val_accuracy: 0.9429
Epoch 32/50
600/600 [==============================] - 344s 573ms/step - loss: 0.0818 - accuracy: 0.9731 - val_loss: 0.1970 - val_accuracy: 0.9479
Epoch 33/50
600/600 [==============================] - 343s 571ms/step - loss: 0.0745 - accuracy: 0.9746 - val_loss: 0.2150 - val_accuracy: 0.9492
Epoch 34/50
600/600 [==============================] - 343s 572ms/step - loss: 0.0752 - accuracy: 0.9734 - val_loss: 0.2410 - val_accuracy: 0.9344
Epoch 35/50
600/600 [==============================] - 344s 573ms/step - loss: 0.0682 - accuracy: 0.9752 - val_loss: 0.2054 - val_accuracy: 0.9502
Epoch 36/50
600/600 [==============================] - 345s 575ms/step - loss: 0.0734 - accuracy: 0.9744 - val_loss: 0.2150 - val_accuracy: 0.9494
Epoch 37/50
600/600 [==============================] - 344s 573ms/step - loss: 0.0685 - accuracy: 0.9762 - val_loss: 0.2184 - val_accuracy: 0.9475
Epoch 38/50
600/600 [==============================] - 342s 571ms/step - loss: 0.0677 - accuracy: 0.9767 - val_loss: 0.2154 - val_accuracy: 0.9492
Epoch 39/50
600/600 [==============================] - 344s 573ms/step - loss: 0.0663 - accuracy: 0.9778 - val_loss: 0.2140 - val_accuracy: 0.9465
Epoch 40/50
600/600 [==============================] - 344s 574ms/step - loss: 0.0688 - accuracy: 0.9773 - val_loss: 0.2552 - val_accuracy: 0.9419
Epoch 41/50
600/600 [==============================] - 344s 573ms/step - loss: 0.0676 - accuracy: 0.9761 - val_loss: 0.2264 - val_accuracy: 0.9494
Epoch 42/50
600/600 [==============================] - 343s 572ms/step - loss: 0.0639 - accuracy: 0.9778 - val_loss: 0.2136 - val_accuracy: 0.9473
Epoch 43/50
600/600 [==============================] - 341s 569ms/step - loss: 0.0720 - accuracy: 0.9771 - val_loss: 0.2191 - val_accuracy: 0.9498
Epoch 44/50
600/600 [==============================] - 344s 573ms/step - loss: 0.0650 - accuracy: 0.9783 - val_loss: 0.2222 - val_accuracy: 0.9506
Epoch 45/50
600/600 [==============================] - 343s 572ms/step - loss: 0.0594 - accuracy: 0.9805 - val_loss: 0.2197 - val_accuracy: 0.9535
Epoch 46/50
600/600 [==============================] - 344s 574ms/step - loss: 0.0556 - accuracy: 0.9811 - val_loss: 0.2530 - val_accuracy: 0.9477
Epoch 47/50
600/600 [==============================] - 345s 575ms/step - loss: 0.0598 - accuracy: 0.9808 - val_loss: 0.2420 - val_accuracy: 0.9490
Epoch 48/50
600/600 [==============================] - 341s 569ms/step - loss: 0.0543 - accuracy: 0.9811 - val_loss: 0.2557 - val_accuracy: 0.9490
Epoch 49/50
600/600 [==============================] - 343s 572ms/step - loss: 0.0588 - accuracy: 0.9795 - val_loss: 0.2295 - val_accuracy: 0.9494
Epoch 50/50
600/600 [==============================] - 343s 572ms/step - loss: 0.0586 - accuracy: 0.9804 - val_loss: 0.2625 - val_accuracy: 0.9504
Model: "model_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 input_6 (InputLayer)        [(None, 64, 64, 3)]       0

 data_augmentation (Sequenti  (None, 64, 64, 3)        0
 al)

 tf.__operators__.getitem_2   (None, 64, 64, 3)        0
 (SlicingOpLambda)

 tf.nn.bias_add_2 (TFOpLambd  (None, 64, 64, 3)        0
 a)

 resnet50 (Functional)       (None, 2, 2, 2048)        23587712

 flatten_2 (Flatten)         (None, 8192)              0

 dense_4 (Dense)             (None, 128)               1048704

 dropout_2 (Dropout)         (None, 128)               0

 dense_5 (Dense)             (None, 10)                1290

=================================================================
Total params: 24,637,706
Trainable params: 24,584,586
Non-trainable params: 53,120
_________________________________________________________________
ResNet50 Model(unfreeze conv5_block1_1_conv): None
Epoch 1/75
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input "contrast_factor" of op 'AdjustContrastv2' expected to be loop invariant.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input "contrast_factor" of op 'AdjustContrastv2' expected to be loop invariant.
600/600 [==============================] - 351s 572ms/step - loss: 0.4244 - accuracy: 0.8705 - val_loss: 0.2676 - val_accuracy: 0.9167
Epoch 2/75
600/600 [==============================] - 341s 568ms/step - loss: 0.2612 - accuracy: 0.9181 - val_loss: 0.3366 - val_accuracy: 0.8998
Epoch 3/75
600/600 [==============================] - 342s 570ms/step - loss: 0.2216 - accuracy: 0.9315 - val_loss: 0.2276 - val_accuracy: 0.9240
Epoch 4/75
600/600 [==============================] - 342s 570ms/step - loss: 0.1889 - accuracy: 0.9393 - val_loss: 0.2046 - val_accuracy: 0.9317
Epoch 5/75
600/600 [==============================] - 341s 568ms/step - loss: 0.1743 - accuracy: 0.9463 - val_loss: 0.2105 - val_accuracy: 0.9290
Epoch 6/75
600/600 [==============================] - 340s 567ms/step - loss: 0.1699 - accuracy: 0.9455 - val_loss: 0.1488 - val_accuracy: 0.9533
Epoch 7/75
600/600 [==============================] - 340s 567ms/step - loss: 0.1478 - accuracy: 0.9544 - val_loss: 0.2070 - val_accuracy: 0.9337
Epoch 8/75
600/600 [==============================] - 341s 569ms/step - loss: 0.1460 - accuracy: 0.9538 - val_loss: 0.3130 - val_accuracy: 0.9106
Epoch 9/75
600/600 [==============================] - 341s 568ms/step - loss: 0.1398 - accuracy: 0.9563 - val_loss: 0.2984 - val_accuracy: 0.9140
Epoch 10/75
600/600 [==============================] - 342s 570ms/step - loss: 0.1077 - accuracy: 0.9646 - val_loss: 0.2732 - val_accuracy: 0.9267
Epoch 11/75
600/600 [==============================] - 342s 570ms/step - loss: 0.1155 - accuracy: 0.9642 - val_loss: 0.1937 - val_accuracy: 0.9427
Epoch 12/75
600/600 [==============================] - 274s 457ms/step - loss: 0.1094 - accuracy: 0.9646 - val_loss: 0.1917 - val_accuracy: 0.9440
Epoch 13/75
600/600 [==============================] - 269s 449ms/step - loss: 0.1070 - accuracy: 0.9674 - val_loss: 0.1934 - val_accuracy: 0.9410
Epoch 14/75
600/600 [==============================] - 328s 547ms/step - loss: 0.0938 - accuracy: 0.9692 - val_loss: 0.3143 - val_accuracy: 0.9142
Epoch 15/75
600/600 [==============================] - 338s 563ms/step - loss: 0.1004 - accuracy: 0.9694 - val_loss: 0.1783 - val_accuracy: 0.9498
Epoch 16/75
600/600 [==============================] - 310s 517ms/step - loss: 0.0935 - accuracy: 0.9709 - val_loss: 0.3323 - val_accuracy: 0.9233
Epoch 17/75
600/600 [==============================] - 337s 562ms/step - loss: 0.0817 - accuracy: 0.9742 - val_loss: 0.1568 - val_accuracy: 0.9519
Epoch 18/75
600/600 [==============================] - 336s 560ms/step - loss: 0.0925 - accuracy: 0.9709 - val_loss: 0.1552 - val_accuracy: 0.9542
Epoch 19/75
600/600 [==============================] - 337s 561ms/step - loss: 0.0677 - accuracy: 0.9773 - val_loss: 0.1996 - val_accuracy: 0.9396
Epoch 20/75
600/600 [==============================] - 337s 561ms/step - loss: 0.0693 - accuracy: 0.9774 - val_loss: 0.2451 - val_accuracy: 0.9362
Epoch 21/75
600/600 [==============================] - 331s 551ms/step - loss: 0.0751 - accuracy: 0.9769 - val_loss: 0.1445 - val_accuracy: 0.9606
Epoch 22/75
600/600 [==============================] - 331s 552ms/step - loss: 0.0639 - accuracy: 0.9809 - val_loss: 0.2338 - val_accuracy: 0.9408
Epoch 23/75
600/600 [==============================] - 321s 535ms/step - loss: 0.0669 - accuracy: 0.9776 - val_loss: 0.2619 - val_accuracy: 0.9285
Epoch 24/75
600/600 [==============================] - 317s 528ms/step - loss: 0.0735 - accuracy: 0.9791 - val_loss: 0.1758 - val_accuracy: 0.9523
Epoch 25/75
600/600 [==============================] - 329s 548ms/step - loss: 0.0607 - accuracy: 0.9817 - val_loss: 0.2577 - val_accuracy: 0.9450
Epoch 26/75
600/600 [==============================] - 336s 561ms/step - loss: 0.0608 - accuracy: 0.9810 - val_loss: 0.1809 - val_accuracy: 0.9431
Epoch 27/75
600/600 [==============================] - 329s 549ms/step - loss: 0.0620 - accuracy: 0.9814 - val_loss: 0.1543 - val_accuracy: 0.9613
Epoch 28/75
600/600 [==============================] - 304s 507ms/step - loss: 0.0574 - accuracy: 0.9814 - val_loss: 0.2323 - val_accuracy: 0.9325
Epoch 29/75
600/600 [==============================] - 334s 557ms/step - loss: 0.0524 - accuracy: 0.9841 - val_loss: 0.1506 - val_accuracy: 0.9579
Epoch 30/75
600/600 [==============================] - 334s 556ms/step - loss: 0.0505 - accuracy: 0.9843 - val_loss: 0.1777 - val_accuracy: 0.9560
Epoch 31/75
600/600 [==============================] - 337s 561ms/step - loss: 0.0530 - accuracy: 0.9846 - val_loss: 0.1555 - val_accuracy: 0.9575
Epoch 32/75
600/600 [==============================] - 331s 551ms/step - loss: 0.0620 - accuracy: 0.9819 - val_loss: 0.1809 - val_accuracy: 0.9544
Epoch 33/75
600/600 [==============================] - 335s 559ms/step - loss: 0.0423 - accuracy: 0.9874 - val_loss: 0.1870 - val_accuracy: 0.9546
Epoch 34/75
600/600 [==============================] - 332s 553ms/step - loss: 0.0471 - accuracy: 0.9867 - val_loss: 0.2717 - val_accuracy: 0.9367
Epoch 35/75
600/600 [==============================] - 332s 554ms/step - loss: 0.0508 - accuracy: 0.9840 - val_loss: 0.1988 - val_accuracy: 0.9556
Epoch 36/75
600/600 [==============================] - 333s 554ms/step - loss: 0.0476 - accuracy: 0.9849 - val_loss: 0.1860 - val_accuracy: 0.9577
Epoch 37/75
600/600 [==============================] - 287s 478ms/step - loss: 0.0411 - accuracy: 0.9877 - val_loss: 0.1758 - val_accuracy: 0.9554
Epoch 38/75
600/600 [==============================] - 319s 532ms/step - loss: 0.0458 - accuracy: 0.9864 - val_loss: 0.1616 - val_accuracy: 0.9592
Epoch 39/75
600/600 [==============================] - 288s 480ms/step - loss: 0.0507 - accuracy: 0.9851 - val_loss: 0.2035 - val_accuracy: 0.9531
Epoch 40/75
600/600 [==============================] - 304s 507ms/step - loss: 0.0464 - accuracy: 0.9857 - val_loss: 0.1733 - val_accuracy: 0.9542
Epoch 41/75
600/600 [==============================] - 340s 567ms/step - loss: 0.0363 - accuracy: 0.9895 - val_loss: 0.1925 - val_accuracy: 0.9573
Epoch 42/75
600/600 [==============================] - 340s 566ms/step - loss: 0.0493 - accuracy: 0.9849 - val_loss: 0.1945 - val_accuracy: 0.9417
Epoch 43/75
600/600 [==============================] - 339s 566ms/step - loss: 0.0372 - accuracy: 0.9883 - val_loss: 0.1928 - val_accuracy: 0.9577
Epoch 44/75
600/600 [==============================] - 342s 570ms/step - loss: 0.0444 - accuracy: 0.9876 - val_loss: 0.2492 - val_accuracy: 0.9431
Epoch 45/75
600/600 [==============================] - 341s 569ms/step - loss: 0.0415 - accuracy: 0.9876 - val_loss: 0.2544 - val_accuracy: 0.9265
Epoch 46/75
600/600 [==============================] - 342s 570ms/step - loss: 0.0413 - accuracy: 0.9879 - val_loss: 0.2093 - val_accuracy: 0.9469
Epoch 47/75
600/600 [==============================] - 341s 568ms/step - loss: 0.0561 - accuracy: 0.9846 - val_loss: 0.1996 - val_accuracy: 0.9473
Epoch 48/75
600/600 [==============================] - 341s 568ms/step - loss: 0.0402 - accuracy: 0.9886 - val_loss: 0.1759 - val_accuracy: 0.9569
Epoch 49/75
600/600 [==============================] - 341s 569ms/step - loss: 0.0312 - accuracy: 0.9903 - val_loss: 0.2095 - val_accuracy: 0.9617
Epoch 50/75
600/600 [==============================] - 342s 570ms/step - loss: 0.0662 - accuracy: 0.9799 - val_loss: 0.2230 - val_accuracy: 0.9469
Epoch 51/75
600/600 [==============================] - 337s 562ms/step - loss: 0.0319 - accuracy: 0.9896 - val_loss: 0.1924 - val_accuracy: 0.9554
Epoch 52/75
600/600 [==============================] - 337s 562ms/step - loss: 0.0325 - accuracy: 0.9913 - val_loss: 0.1941 - val_accuracy: 0.9546
Epoch 53/75
600/600 [==============================] - 339s 565ms/step - loss: 0.0329 - accuracy: 0.9907 - val_loss: 0.2530 - val_accuracy: 0.9442
Epoch 54/75
600/600 [==============================] - 339s 565ms/step - loss: 0.0256 - accuracy: 0.9928 - val_loss: 0.1725 - val_accuracy: 0.9663
Epoch 55/75
600/600 [==============================] - 336s 561ms/step - loss: 0.0404 - accuracy: 0.9884 - val_loss: 0.1912 - val_accuracy: 0.9548
Epoch 56/75
600/600 [==============================] - 336s 560ms/step - loss: 0.0413 - accuracy: 0.9882 - val_loss: 0.2021 - val_accuracy: 0.9458
Epoch 57/75
600/600 [==============================] - 336s 560ms/step - loss: 0.0451 - accuracy: 0.9861 - val_loss: 0.4511 - val_accuracy: 0.9006
Epoch 58/75
600/600 [==============================] - 329s 549ms/step - loss: 0.0287 - accuracy: 0.9912 - val_loss: 0.2183 - val_accuracy: 0.9521
Epoch 59/75
600/600 [==============================] - 272s 453ms/step - loss: 0.0358 - accuracy: 0.9896 - val_loss: 0.2155 - val_accuracy: 0.9523
Epoch 60/75
600/600 [==============================] - 271s 452ms/step - loss: 0.0334 - accuracy: 0.9899 - val_loss: 0.2442 - val_accuracy: 0.9558
Epoch 61/75
600/600 [==============================] - 270s 451ms/step - loss: 0.0253 - accuracy: 0.9920 - val_loss: 0.2433 - val_accuracy: 0.9494
Epoch 62/75
600/600 [==============================] - 270s 450ms/step - loss: 0.0360 - accuracy: 0.9905 - val_loss: 0.1909 - val_accuracy: 0.9540
Epoch 63/75
600/600 [==============================] - 269s 448ms/step - loss: 0.0357 - accuracy: 0.9895 - val_loss: 0.2450 - val_accuracy: 0.9504
Epoch 64/75
600/600 [==============================] - 269s 449ms/step - loss: 0.0307 - accuracy: 0.9903 - val_loss: 0.2693 - val_accuracy: 0.9348
Epoch 65/75
600/600 [==============================] - 268s 447ms/step - loss: 0.0736 - accuracy: 0.9786 - val_loss: 0.2517 - val_accuracy: 0.9413
Epoch 66/75
600/600 [==============================] - 268s 447ms/step - loss: 0.0442 - accuracy: 0.9865 - val_loss: 0.2080 - val_accuracy: 0.9558
Epoch 67/75
600/600 [==============================] - 269s 449ms/step - loss: 0.0311 - accuracy: 0.9905 - val_loss: 0.1565 - val_accuracy: 0.9550
Epoch 68/75
600/600 [==============================] - 268s 447ms/step - loss: 0.0231 - accuracy: 0.9927 - val_loss: 0.2920 - val_accuracy: 0.9506
Epoch 69/75
600/600 [==============================] - 275s 458ms/step - loss: 0.0279 - accuracy: 0.9918 - val_loss: 0.2437 - val_accuracy: 0.9577
Epoch 70/75
600/600 [==============================] - 332s 554ms/step - loss: 0.0248 - accuracy: 0.9930 - val_loss: 0.1964 - val_accuracy: 0.9600
Epoch 71/75
600/600 [==============================] - 292s 487ms/step - loss: 0.0420 - accuracy: 0.9883 - val_loss: 0.2710 - val_accuracy: 0.9479
Epoch 72/75
600/600 [==============================] - 324s 540ms/step - loss: 0.0309 - accuracy: 0.9902 - val_loss: 0.2285 - val_accuracy: 0.9492
Epoch 73/75
600/600 [==============================] - 320s 534ms/step - loss: 0.0347 - accuracy: 0.9901 - val_loss: 0.2040 - val_accuracy: 0.9440
Epoch 74/75
600/600 [==============================] - 337s 561ms/step - loss: 0.0283 - accuracy: 0.9924 - val_loss: 0.2047 - val_accuracy: 0.9552
Epoch 75/75
600/600 [==============================] - 334s 558ms/step - loss: 0.0315 - accuracy: 0.9907 - val_loss: 0.3054 - val_accuracy: 0.9375
=======================================================================================================

Process finished with exit code 0