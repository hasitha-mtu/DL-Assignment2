C:\Users\AdikariAdikari\anaconda3\envs\tf\python.exe C:\Users\AdikariAdikari\PycharmProjects\DL-Assignment2\question3.py
[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
physical_devices : [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
2.10.1
True
(19200, 64, 64, 3) (19200,)
(4800, 64, 64, 3) (4800,)
Single input shape: (64, 64, 3)
2025-05-08 20:19:29.319011: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-05-08 20:19:31.244022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5409 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9
Model: "resnet50"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to
==================================================================================================
 input_1 (InputLayer)           [(None, 64, 64, 3)]  0           []

 conv1_pad (ZeroPadding2D)      (None, 70, 70, 3)    0           ['input_1[0][0]']

 conv1_conv (Conv2D)            (None, 32, 32, 64)   9472        ['conv1_pad[0][0]']

 conv1_bn (BatchNormalization)  (None, 32, 32, 64)   256         ['conv1_conv[0][0]']

 conv1_relu (Activation)        (None, 32, 32, 64)   0           ['conv1_bn[0][0]']

 pool1_pad (ZeroPadding2D)      (None, 34, 34, 64)   0           ['conv1_relu[0][0]']

 pool1_pool (MaxPooling2D)      (None, 16, 16, 64)   0           ['pool1_pad[0][0]']

 conv2_block1_1_conv (Conv2D)   (None, 16, 16, 64)   4160        ['pool1_pool[0][0]']

 conv2_block1_1_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block1_1_conv[0][0]']
 ization)

 conv2_block1_1_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block1_1_bn[0][0]']
 n)

 conv2_block1_2_conv (Conv2D)   (None, 16, 16, 64)   36928       ['conv2_block1_1_relu[0][0]']

 conv2_block1_2_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block1_2_conv[0][0]']
 ization)

 conv2_block1_2_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block1_2_bn[0][0]']
 n)

 conv2_block1_0_conv (Conv2D)   (None, 16, 16, 256)  16640       ['pool1_pool[0][0]']

 conv2_block1_3_conv (Conv2D)   (None, 16, 16, 256)  16640       ['conv2_block1_2_relu[0][0]']

 conv2_block1_0_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv2_block1_0_conv[0][0]']
 ization)

 conv2_block1_3_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv2_block1_3_conv[0][0]']
 ization)

 conv2_block1_add (Add)         (None, 16, 16, 256)  0           ['conv2_block1_0_bn[0][0]',
                                                                  'conv2_block1_3_bn[0][0]']

 conv2_block1_out (Activation)  (None, 16, 16, 256)  0           ['conv2_block1_add[0][0]']

 conv2_block2_1_conv (Conv2D)   (None, 16, 16, 64)   16448       ['conv2_block1_out[0][0]']

 conv2_block2_1_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block2_1_conv[0][0]']
 ization)

 conv2_block2_1_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block2_1_bn[0][0]']
 n)

 conv2_block2_2_conv (Conv2D)   (None, 16, 16, 64)   36928       ['conv2_block2_1_relu[0][0]']

 conv2_block2_2_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block2_2_conv[0][0]']
 ization)

 conv2_block2_2_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block2_2_bn[0][0]']
 n)

 conv2_block2_3_conv (Conv2D)   (None, 16, 16, 256)  16640       ['conv2_block2_2_relu[0][0]']

 conv2_block2_3_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv2_block2_3_conv[0][0]']
 ization)

 conv2_block2_add (Add)         (None, 16, 16, 256)  0           ['conv2_block1_out[0][0]',
                                                                  'conv2_block2_3_bn[0][0]']

 conv2_block2_out (Activation)  (None, 16, 16, 256)  0           ['conv2_block2_add[0][0]']

 conv2_block3_1_conv (Conv2D)   (None, 16, 16, 64)   16448       ['conv2_block2_out[0][0]']

 conv2_block3_1_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block3_1_conv[0][0]']
 ization)

 conv2_block3_1_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block3_1_bn[0][0]']
 n)

 conv2_block3_2_conv (Conv2D)   (None, 16, 16, 64)   36928       ['conv2_block3_1_relu[0][0]']

 conv2_block3_2_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block3_2_conv[0][0]']
 ization)

 conv2_block3_2_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block3_2_bn[0][0]']
 n)

 conv2_block3_3_conv (Conv2D)   (None, 16, 16, 256)  16640       ['conv2_block3_2_relu[0][0]']

 conv2_block3_3_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv2_block3_3_conv[0][0]']
 ization)

 conv2_block3_add (Add)         (None, 16, 16, 256)  0           ['conv2_block2_out[0][0]',
                                                                  'conv2_block3_3_bn[0][0]']

 conv2_block3_out (Activation)  (None, 16, 16, 256)  0           ['conv2_block3_add[0][0]']

 conv3_block1_1_conv (Conv2D)   (None, 8, 8, 128)    32896       ['conv2_block3_out[0][0]']

 conv3_block1_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block1_1_conv[0][0]']
 ization)

 conv3_block1_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block1_1_bn[0][0]']
 n)

 conv3_block1_2_conv (Conv2D)   (None, 8, 8, 128)    147584      ['conv3_block1_1_relu[0][0]']

 conv3_block1_2_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block1_2_conv[0][0]']
 ization)

 conv3_block1_2_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block1_2_bn[0][0]']
 n)

 conv3_block1_0_conv (Conv2D)   (None, 8, 8, 512)    131584      ['conv2_block3_out[0][0]']

 conv3_block1_3_conv (Conv2D)   (None, 8, 8, 512)    66048       ['conv3_block1_2_relu[0][0]']

 conv3_block1_0_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv3_block1_0_conv[0][0]']
 ization)

 conv3_block1_3_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv3_block1_3_conv[0][0]']
 ization)

 conv3_block1_add (Add)         (None, 8, 8, 512)    0           ['conv3_block1_0_bn[0][0]',
                                                                  'conv3_block1_3_bn[0][0]']

 conv3_block1_out (Activation)  (None, 8, 8, 512)    0           ['conv3_block1_add[0][0]']

 conv3_block2_1_conv (Conv2D)   (None, 8, 8, 128)    65664       ['conv3_block1_out[0][0]']

 conv3_block2_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block2_1_conv[0][0]']
 ization)

 conv3_block2_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block2_1_bn[0][0]']
 n)

 conv3_block2_2_conv (Conv2D)   (None, 8, 8, 128)    147584      ['conv3_block2_1_relu[0][0]']

 conv3_block2_2_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block2_2_conv[0][0]']
 ization)

 conv3_block2_2_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block2_2_bn[0][0]']
 n)

 conv3_block2_3_conv (Conv2D)   (None, 8, 8, 512)    66048       ['conv3_block2_2_relu[0][0]']

 conv3_block2_3_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv3_block2_3_conv[0][0]']
 ization)

 conv3_block2_add (Add)         (None, 8, 8, 512)    0           ['conv3_block1_out[0][0]',
                                                                  'conv3_block2_3_bn[0][0]']

 conv3_block2_out (Activation)  (None, 8, 8, 512)    0           ['conv3_block2_add[0][0]']

 conv3_block3_1_conv (Conv2D)   (None, 8, 8, 128)    65664       ['conv3_block2_out[0][0]']

 conv3_block3_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block3_1_conv[0][0]']
 ization)

 conv3_block3_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block3_1_bn[0][0]']
 n)

 conv3_block3_2_conv (Conv2D)   (None, 8, 8, 128)    147584      ['conv3_block3_1_relu[0][0]']

 conv3_block3_2_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block3_2_conv[0][0]']
 ization)

 conv3_block3_2_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block3_2_bn[0][0]']
 n)

 conv3_block3_3_conv (Conv2D)   (None, 8, 8, 512)    66048       ['conv3_block3_2_relu[0][0]']

 conv3_block3_3_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv3_block3_3_conv[0][0]']
 ization)

 conv3_block3_add (Add)         (None, 8, 8, 512)    0           ['conv3_block2_out[0][0]',
                                                                  'conv3_block3_3_bn[0][0]']

 conv3_block3_out (Activation)  (None, 8, 8, 512)    0           ['conv3_block3_add[0][0]']

 conv3_block4_1_conv (Conv2D)   (None, 8, 8, 128)    65664       ['conv3_block3_out[0][0]']

 conv3_block4_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block4_1_conv[0][0]']
 ization)

 conv3_block4_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block4_1_bn[0][0]']
 n)

 conv3_block4_2_conv (Conv2D)   (None, 8, 8, 128)    147584      ['conv3_block4_1_relu[0][0]']

 conv3_block4_2_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block4_2_conv[0][0]']
 ization)

 conv3_block4_2_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block4_2_bn[0][0]']
 n)

 conv3_block4_3_conv (Conv2D)   (None, 8, 8, 512)    66048       ['conv3_block4_2_relu[0][0]']

 conv3_block4_3_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv3_block4_3_conv[0][0]']
 ization)

 conv3_block4_add (Add)         (None, 8, 8, 512)    0           ['conv3_block3_out[0][0]',
                                                                  'conv3_block4_3_bn[0][0]']

 conv3_block4_out (Activation)  (None, 8, 8, 512)    0           ['conv3_block4_add[0][0]']

 conv4_block1_1_conv (Conv2D)   (None, 4, 4, 256)    131328      ['conv3_block4_out[0][0]']

 conv4_block1_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block1_1_conv[0][0]']
 ization)

 conv4_block1_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block1_1_bn[0][0]']
 n)

 conv4_block1_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block1_1_relu[0][0]']

 conv4_block1_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block1_2_conv[0][0]']
 ization)

 conv4_block1_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block1_2_bn[0][0]']
 n)

 conv4_block1_0_conv (Conv2D)   (None, 4, 4, 1024)   525312      ['conv3_block4_out[0][0]']

 conv4_block1_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block1_2_relu[0][0]']

 conv4_block1_0_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block1_0_conv[0][0]']
 ization)

 conv4_block1_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block1_3_conv[0][0]']
 ization)

 conv4_block1_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block1_0_bn[0][0]',
                                                                  'conv4_block1_3_bn[0][0]']

 conv4_block1_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block1_add[0][0]']

 conv4_block2_1_conv (Conv2D)   (None, 4, 4, 256)    262400      ['conv4_block1_out[0][0]']

 conv4_block2_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block2_1_conv[0][0]']
 ization)

 conv4_block2_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block2_1_bn[0][0]']
 n)

 conv4_block2_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block2_1_relu[0][0]']

 conv4_block2_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block2_2_conv[0][0]']
 ization)

 conv4_block2_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block2_2_bn[0][0]']
 n)

 conv4_block2_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block2_2_relu[0][0]']

 conv4_block2_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block2_3_conv[0][0]']
 ization)

 conv4_block2_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block1_out[0][0]',
                                                                  'conv4_block2_3_bn[0][0]']

 conv4_block2_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block2_add[0][0]']

 conv4_block3_1_conv (Conv2D)   (None, 4, 4, 256)    262400      ['conv4_block2_out[0][0]']

 conv4_block3_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block3_1_conv[0][0]']
 ization)

 conv4_block3_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block3_1_bn[0][0]']
 n)

 conv4_block3_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block3_1_relu[0][0]']

 conv4_block3_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block3_2_conv[0][0]']
 ization)

 conv4_block3_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block3_2_bn[0][0]']
 n)

 conv4_block3_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block3_2_relu[0][0]']

 conv4_block3_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block3_3_conv[0][0]']
 ization)

 conv4_block3_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block2_out[0][0]',
                                                                  'conv4_block3_3_bn[0][0]']

 conv4_block3_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block3_add[0][0]']

 conv4_block4_1_conv (Conv2D)   (None, 4, 4, 256)    262400      ['conv4_block3_out[0][0]']

 conv4_block4_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block4_1_conv[0][0]']
 ization)

 conv4_block4_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block4_1_bn[0][0]']
 n)

 conv4_block4_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block4_1_relu[0][0]']

 conv4_block4_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block4_2_conv[0][0]']
 ization)

 conv4_block4_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block4_2_bn[0][0]']
 n)

 conv4_block4_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block4_2_relu[0][0]']

 conv4_block4_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block4_3_conv[0][0]']
 ization)

 conv4_block4_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block3_out[0][0]',
                                                                  'conv4_block4_3_bn[0][0]']

 conv4_block4_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block4_add[0][0]']

 conv4_block5_1_conv (Conv2D)   (None, 4, 4, 256)    262400      ['conv4_block4_out[0][0]']

 conv4_block5_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block5_1_conv[0][0]']
 ization)

 conv4_block5_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block5_1_bn[0][0]']
 n)

 conv4_block5_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block5_1_relu[0][0]']

 conv4_block5_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block5_2_conv[0][0]']
 ization)

 conv4_block5_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block5_2_bn[0][0]']
 n)

 conv4_block5_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block5_2_relu[0][0]']

 conv4_block5_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block5_3_conv[0][0]']
 ization)

 conv4_block5_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block4_out[0][0]',
                                                                  'conv4_block5_3_bn[0][0]']

 conv4_block5_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block5_add[0][0]']

 conv4_block6_1_conv (Conv2D)   (None, 4, 4, 256)    262400      ['conv4_block5_out[0][0]']

 conv4_block6_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block6_1_conv[0][0]']
 ization)

 conv4_block6_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block6_1_bn[0][0]']
 n)

 conv4_block6_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block6_1_relu[0][0]']

 conv4_block6_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block6_2_conv[0][0]']
 ization)

 conv4_block6_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block6_2_bn[0][0]']
 n)

 conv4_block6_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block6_2_relu[0][0]']

 conv4_block6_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block6_3_conv[0][0]']
 ization)

 conv4_block6_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block5_out[0][0]',
                                                                  'conv4_block6_3_bn[0][0]']

 conv4_block6_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block6_add[0][0]']

 conv5_block1_1_conv (Conv2D)   (None, 2, 2, 512)    524800      ['conv4_block6_out[0][0]']

 conv5_block1_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block1_1_conv[0][0]']
 ization)

 conv5_block1_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block1_1_bn[0][0]']
 n)

 conv5_block1_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block1_1_relu[0][0]']

 conv5_block1_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block1_2_conv[0][0]']
 ization)

 conv5_block1_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block1_2_bn[0][0]']
 n)

 conv5_block1_0_conv (Conv2D)   (None, 2, 2, 2048)   2099200     ['conv4_block6_out[0][0]']

 conv5_block1_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block1_2_relu[0][0]']

 conv5_block1_0_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block1_0_conv[0][0]']
 ization)

 conv5_block1_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block1_3_conv[0][0]']
 ization)

 conv5_block1_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block1_0_bn[0][0]',
                                                                  'conv5_block1_3_bn[0][0]']

 conv5_block1_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block1_add[0][0]']

 conv5_block2_1_conv (Conv2D)   (None, 2, 2, 512)    1049088     ['conv5_block1_out[0][0]']

 conv5_block2_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block2_1_conv[0][0]']
 ization)

 conv5_block2_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block2_1_bn[0][0]']
 n)

 conv5_block2_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block2_1_relu[0][0]']

 conv5_block2_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block2_2_conv[0][0]']
 ization)

 conv5_block2_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block2_2_bn[0][0]']
 n)

 conv5_block2_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block2_2_relu[0][0]']

 conv5_block2_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block2_3_conv[0][0]']
 ization)

 conv5_block2_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block1_out[0][0]',
                                                                  'conv5_block2_3_bn[0][0]']

 conv5_block2_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block2_add[0][0]']

 conv5_block3_1_conv (Conv2D)   (None, 2, 2, 512)    1049088     ['conv5_block2_out[0][0]']

 conv5_block3_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block3_1_conv[0][0]']
 ization)

 conv5_block3_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block3_1_bn[0][0]']
 n)

 conv5_block3_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block3_1_relu[0][0]']

 conv5_block3_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block3_2_conv[0][0]']
 ization)

 conv5_block3_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block3_2_bn[0][0]']
 n)

 conv5_block3_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block3_2_relu[0][0]']

 conv5_block3_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block3_3_conv[0][0]']
 ization)

 conv5_block3_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block2_out[0][0]',
                                                                  'conv5_block3_3_bn[0][0]']

 conv5_block3_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block3_add[0][0]']

 avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']
 2D)

==================================================================================================
Total params: 23,587,712
Trainable params: 0
Non-trainable params: 23,587,712
__________________________________________________________________________________________________
ResNet50 Base model: None
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 input_2 (InputLayer)        [(None, 64, 64, 3)]       0

 data_augmentation (Sequenti  (None, 64, 64, 3)        0
 al)

 tf.__operators__.getitem (S  (None, 64, 64, 3)        0
 licingOpLambda)

 tf.nn.bias_add (TFOpLambda)  (None, 64, 64, 3)        0

 resnet50 (Functional)       (None, 2048)              23587712

 flatten (Flatten)           (None, 2048)              0

 dense (Dense)               (None, 128)               262272

 dropout (Dropout)           (None, 128)               0

 dense_1 (Dense)             (None, 10)                1290

=================================================================
Total params: 23,851,274
Trainable params: 263,562
Non-trainable params: 23,587,712
_________________________________________________________________
ResNet50 Model: None
Epoch 1/25
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input "contrast_factor" of op 'AdjustContrastv2' expected to be loop invariant.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input "contrast_factor" of op 'AdjustContrastv2' expected to be loop invariant.
2025-05-08 20:19:46.819460: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100
2025-05-08 20:19:55.325369: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
600/600 [==============================] - 272s 419ms/step - loss: 1.1545 - accuracy: 0.6430 - val_loss: 0.4223 - val_accuracy: 0.8727
Epoch 2/25
600/600 [==============================] - 295s 492ms/step - loss: 0.5976 - accuracy: 0.8081 - val_loss: 0.3345 - val_accuracy: 0.8938
Epoch 3/25
600/600 [==============================] - 263s 438ms/step - loss: 0.4901 - accuracy: 0.8390 - val_loss: 0.2988 - val_accuracy: 0.9019
Epoch 4/25
600/600 [==============================] - 407s 680ms/step - loss: 0.4406 - accuracy: 0.8574 - val_loss: 0.2838 - val_accuracy: 0.9046
Epoch 5/25
600/600 [==============================] - 341s 569ms/step - loss: 0.3969 - accuracy: 0.8702 - val_loss: 0.2663 - val_accuracy: 0.9125
Epoch 6/25
600/600 [==============================] - 343s 571ms/step - loss: 0.3759 - accuracy: 0.8753 - val_loss: 0.2568 - val_accuracy: 0.9148
Epoch 7/25
600/600 [==============================] - 632s 1s/step - loss: 0.3459 - accuracy: 0.8853 - val_loss: 0.2462 - val_accuracy: 0.9171
Epoch 8/25
600/600 [==============================] - 636s 1s/step - loss: 0.3407 - accuracy: 0.8841 - val_loss: 0.2352 - val_accuracy: 0.9208
Epoch 9/25
600/600 [==============================] - 310s 518ms/step - loss: 0.3271 - accuracy: 0.8921 - val_loss: 0.2296 - val_accuracy: 0.9219
Epoch 10/25
600/600 [==============================] - 364s 607ms/step - loss: 0.3105 - accuracy: 0.8956 - val_loss: 0.2297 - val_accuracy: 0.9200
Epoch 11/25
600/600 [==============================] - 364s 607ms/step - loss: 0.3010 - accuracy: 0.8983 - val_loss: 0.2201 - val_accuracy: 0.9273
Epoch 12/25
600/600 [==============================] - 305s 508ms/step - loss: 0.2991 - accuracy: 0.8990 - val_loss: 0.2171 - val_accuracy: 0.9254
Epoch 13/25
600/600 [==============================] - 266s 443ms/step - loss: 0.2841 - accuracy: 0.9062 - val_loss: 0.2149 - val_accuracy: 0.9281
Epoch 14/25
600/600 [==============================] - 263s 439ms/step - loss: 0.2699 - accuracy: 0.9099 - val_loss: 0.2175 - val_accuracy: 0.9260
Epoch 15/25
600/600 [==============================] - 257s 428ms/step - loss: 0.2687 - accuracy: 0.9089 - val_loss: 0.2094 - val_accuracy: 0.9296
Epoch 16/25
600/600 [==============================] - 259s 431ms/step - loss: 0.2645 - accuracy: 0.9089 - val_loss: 0.2099 - val_accuracy: 0.9292
Epoch 17/25
600/600 [==============================] - 263s 439ms/step - loss: 0.2596 - accuracy: 0.9130 - val_loss: 0.2064 - val_accuracy: 0.9325
Epoch 18/25
600/600 [==============================] - 258s 430ms/step - loss: 0.2480 - accuracy: 0.9141 - val_loss: 0.2075 - val_accuracy: 0.9312
Epoch 19/25
600/600 [==============================] - 276s 460ms/step - loss: 0.2516 - accuracy: 0.9157 - val_loss: 0.2034 - val_accuracy: 0.9331
Epoch 20/25
600/600 [==============================] - 262s 437ms/step - loss: 0.2483 - accuracy: 0.9142 - val_loss: 0.2088 - val_accuracy: 0.9298
Epoch 21/25
600/600 [==============================] - 271s 452ms/step - loss: 0.2460 - accuracy: 0.9190 - val_loss: 0.2036 - val_accuracy: 0.9329
Epoch 22/25
600/600 [==============================] - 267s 444ms/step - loss: 0.2324 - accuracy: 0.9182 - val_loss: 0.2058 - val_accuracy: 0.9323
Epoch 23/25
600/600 [==============================] - 261s 435ms/step - loss: 0.2319 - accuracy: 0.9210 - val_loss: 0.2025 - val_accuracy: 0.9317
Epoch 24/25
600/600 [==============================] - 256s 426ms/step - loss: 0.2296 - accuracy: 0.9206 - val_loss: 0.2070 - val_accuracy: 0.9306
Epoch 25/25
600/600 [==============================] - 263s 437ms/step - loss: 0.2317 - accuracy: 0.9206 - val_loss: 0.2046 - val_accuracy: 0.9310
ResNet50 phase A history: {'loss': [1.15451180934906, 0.5975751876831055, 0.4901290833950043, 0.4406401515007019, 0.39685025811195374, 0.37588727474212646, 0.34585943818092346, 0.34065932035446167, 0.3270883560180664, 0.3105405569076538, 0.3009602427482605, 0.299131840467453, 0.28411558270454407, 0.26990583539009094, 0.26874980330467224, 0.2644716203212738, 0.2595730721950531, 0.24800539016723633, 0.2516280710697174, 0.2482612133026123, 0.24595698714256287, 0.2324179857969284, 0.23186075687408447, 0.2295854240655899, 0.2316741645336151], 'accuracy': [0.6430208086967468, 0.8080729246139526, 0.8390104174613953, 0.8573958277702332, 0.8702083230018616, 0.8752604126930237, 0.8853124976158142, 0.8840625286102295, 0.8920833468437195, 0.8956249952316284, 0.8982812762260437, 0.8989583253860474, 0.9061979055404663, 0.9098958373069763, 0.9088541865348816, 0.9088541865348816, 0.9129687547683716, 0.9141145944595337, 0.9157291650772095, 0.9141666889190674, 0.9190104007720947, 0.91817706823349, 0.9210416674613953, 0.9206249713897705, 0.9206249713897705], 'val_loss': [0.42232266068458557, 0.3344734013080597, 0.29883021116256714, 0.283767431974411, 0.266264408826828, 0.2567853033542633, 0.2461603581905365, 0.23520202934741974, 0.22956469655036926, 0.22969968616962433, 0.22011876106262207, 0.2171485424041748, 0.21489712595939636, 0.21750709414482117, 0.20938889682292938, 0.20994026958942413, 0.206355020403862, 0.20752187073230743, 0.20340807735919952, 0.20880021154880524, 0.20356979966163635, 0.20583763718605042, 0.202469140291214, 0.20696549117565155, 0.20461823046207428], 'val_accuracy': [0.8727083206176758, 0.893750011920929, 0.9018750190734863, 0.9045833349227905, 0.9125000238418579, 0.9147916436195374, 0.9170833230018616, 0.9208333492279053, 0.921875, 0.9200000166893005, 0.9272916913032532, 0.9254166483879089, 0.9281250238418579, 0.9260416626930237, 0.9295833110809326, 0.9291666746139526, 0.9325000047683716, 0.9312499761581421, 0.9331250190734863, 0.9297916889190674, 0.9329166412353516, 0.9322916865348816, 0.9316666722297668, 0.9306250214576721, 0.9310416579246521]}
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 input_2 (InputLayer)        [(None, 64, 64, 3)]       0

 data_augmentation (Sequenti  (None, 64, 64, 3)        0
 al)

 tf.__operators__.getitem (S  (None, 64, 64, 3)        0
 licingOpLambda)

 tf.nn.bias_add (TFOpLambda)  (None, 64, 64, 3)        0

 resnet50 (Functional)       (None, 2048)              23587712

 flatten (Flatten)           (None, 2048)              0

 dense (Dense)               (None, 128)               262272

 dropout (Dropout)           (None, 128)               0

 dense_1 (Dense)             (None, 10)                1290

=================================================================
Total params: 23,851,274
Trainable params: 4,729,226
Non-trainable params: 19,122,048
_________________________________________________________________
ResNet50 Model: None
Epoch 1/25
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input "contrast_factor" of op 'AdjustContrastv2' expected to be loop invariant.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input "contrast_factor" of op 'AdjustContrastv2' expected to be loop invariant.
600/600 [==============================] - ETA: 0s - loss: 0.2397 - accuracy: 0.9178
Epoch 1: val_accuracy improved from -inf to 0.93813, saving model to models\resnet50.h5
600/600 [==============================] - 245s 397ms/step - loss: 0.2397 - accuracy: 0.9178 - val_loss: 0.1857 - val_accuracy: 0.9381
Epoch 2/25
600/600 [==============================] - ETA: 0s - loss: 0.2175 - accuracy: 0.9268
Epoch 2: val_accuracy did not improve from 0.93813
600/600 [==============================] - 253s 422ms/step - loss: 0.2175 - accuracy: 0.9268 - val_loss: 0.1897 - val_accuracy: 0.9335
Epoch 3/25
600/600 [==============================] - ETA: 0s - loss: 0.2079 - accuracy: 0.9293
Epoch 3: val_accuracy did not improve from 0.93813
600/600 [==============================] - 234s 389ms/step - loss: 0.2079 - accuracy: 0.9293 - val_loss: 0.1780 - val_accuracy: 0.9371
Epoch 4/25
600/600 [==============================] - ETA: 0s - loss: 0.2004 - accuracy: 0.9315
Epoch 4: val_accuracy did not improve from 0.93813
600/600 [==============================] - 249s 414ms/step - loss: 0.2004 - accuracy: 0.9315 - val_loss: 0.1857 - val_accuracy: 0.9344
Epoch 5/25
600/600 [==============================] - ETA: 0s - loss: 0.1960 - accuracy: 0.9332
Epoch 5: val_accuracy improved from 0.93813 to 0.93979, saving model to models\resnet50.h5
600/600 [==============================] - 246s 410ms/step - loss: 0.1960 - accuracy: 0.9332 - val_loss: 0.1786 - val_accuracy: 0.9398
Epoch 6/25
600/600 [==============================] - ETA: 0s - loss: 0.1854 - accuracy: 0.9344
Epoch 6: val_accuracy did not improve from 0.93979
600/600 [==============================] - 245s 408ms/step - loss: 0.1854 - accuracy: 0.9344 - val_loss: 0.1758 - val_accuracy: 0.9381
Epoch 7/25
600/600 [==============================] - ETA: 0s - loss: 0.1741 - accuracy: 0.9403
Epoch 7: val_accuracy improved from 0.93979 to 0.94042, saving model to models\resnet50.h5
600/600 [==============================] - 245s 408ms/step - loss: 0.1741 - accuracy: 0.9403 - val_loss: 0.1721 - val_accuracy: 0.9404
Epoch 8/25
600/600 [==============================] - ETA: 0s - loss: 0.1689 - accuracy: 0.9421
Epoch 8: val_accuracy did not improve from 0.94042
600/600 [==============================] - 247s 413ms/step - loss: 0.1689 - accuracy: 0.9421 - val_loss: 0.1819 - val_accuracy: 0.9400
Epoch 9/25
600/600 [==============================] - ETA: 0s - loss: 0.1569 - accuracy: 0.9480
Epoch 9: val_accuracy did not improve from 0.94042
600/600 [==============================] - 255s 426ms/step - loss: 0.1569 - accuracy: 0.9480 - val_loss: 0.1811 - val_accuracy: 0.9383
Epoch 10/25
600/600 [==============================] - ETA: 0s - loss: 0.1607 - accuracy: 0.9459
Epoch 10: val_accuracy did not improve from 0.94042
600/600 [==============================] - 245s 409ms/step - loss: 0.1607 - accuracy: 0.9459 - val_loss: 0.2056 - val_accuracy: 0.9356
Epoch 11/25
600/600 [==============================] - ETA: 0s - loss: 0.1490 - accuracy: 0.9500
Epoch 11: val_accuracy did not improve from 0.94042
600/600 [==============================] - 246s 411ms/step - loss: 0.1490 - accuracy: 0.9500 - val_loss: 0.2000 - val_accuracy: 0.9337
Epoch 12/25
600/600 [==============================] - ETA: 0s - loss: 0.1367 - accuracy: 0.9557
Epoch 12: val_accuracy did not improve from 0.94042
600/600 [==============================] - 220s 366ms/step - loss: 0.1367 - accuracy: 0.9557 - val_loss: 0.2049 - val_accuracy: 0.9379
Epoch 13/25
600/600 [==============================] - ETA: 0s - loss: 0.1324 - accuracy: 0.9532
Epoch 13: val_accuracy did not improve from 0.94042
600/600 [==============================] - 199s 333ms/step - loss: 0.1324 - accuracy: 0.9532 - val_loss: 0.1813 - val_accuracy: 0.9381
Epoch 14/25
600/600 [==============================] - ETA: 0s - loss: 0.1262 - accuracy: 0.9593
Epoch 14: val_accuracy improved from 0.94042 to 0.94313, saving model to models\resnet50.h5
600/600 [==============================] - 198s 331ms/step - loss: 0.1262 - accuracy: 0.9593 - val_loss: 0.1892 - val_accuracy: 0.9431
Epoch 15/25
600/600 [==============================] - ETA: 0s - loss: 0.1196 - accuracy: 0.9602
Epoch 15: val_accuracy did not improve from 0.94313
600/600 [==============================] - 207s 346ms/step - loss: 0.1196 - accuracy: 0.9602 - val_loss: 0.2200 - val_accuracy: 0.9331
Epoch 16/25
600/600 [==============================] - ETA: 0s - loss: 0.1092 - accuracy: 0.9636
Epoch 16: val_accuracy did not improve from 0.94313
600/600 [==============================] - 212s 354ms/step - loss: 0.1092 - accuracy: 0.9636 - val_loss: 0.2255 - val_accuracy: 0.9340
Epoch 17/25
600/600 [==============================] - ETA: 0s - loss: 0.1103 - accuracy: 0.9628
Epoch 17: val_accuracy did not improve from 0.94313
600/600 [==============================] - 226s 376ms/step - loss: 0.1103 - accuracy: 0.9628 - val_loss: 0.2120 - val_accuracy: 0.9377
Epoch 18/25
600/600 [==============================] - ETA: 0s - loss: 0.1013 - accuracy: 0.9667
Epoch 18: val_accuracy did not improve from 0.94313
600/600 [==============================] - 237s 396ms/step - loss: 0.1013 - accuracy: 0.9667 - val_loss: 0.1925 - val_accuracy: 0.9417
Epoch 19/25
600/600 [==============================] - ETA: 0s - loss: 0.1027 - accuracy: 0.9635
Epoch 19: val_accuracy did not improve from 0.94313
600/600 [==============================] - 222s 370ms/step - loss: 0.1027 - accuracy: 0.9635 - val_loss: 0.2171 - val_accuracy: 0.9367
Epoch 20/25
600/600 [==============================] - ETA: 0s - loss: 0.0926 - accuracy: 0.9688
Epoch 20: val_accuracy did not improve from 0.94313
600/600 [==============================] - 250s 418ms/step - loss: 0.0926 - accuracy: 0.9688 - val_loss: 0.2050 - val_accuracy: 0.9423
Epoch 21/25
600/600 [==============================] - ETA: 0s - loss: 0.0906 - accuracy: 0.9703
Epoch 21: val_accuracy did not improve from 0.94313
600/600 [==============================] - 239s 398ms/step - loss: 0.0906 - accuracy: 0.9703 - val_loss: 0.2147 - val_accuracy: 0.9396
Epoch 22/25
600/600 [==============================] - ETA: 0s - loss: 0.0881 - accuracy: 0.9705
Epoch 22: val_accuracy did not improve from 0.94313
600/600 [==============================] - 225s 375ms/step - loss: 0.0881 - accuracy: 0.9705 - val_loss: 0.2668 - val_accuracy: 0.9352
Epoch 23/25
600/600 [==============================] - ETA: 0s - loss: 0.0821 - accuracy: 0.9724
Epoch 23: val_accuracy did not improve from 0.94313
600/600 [==============================] - 267s 446ms/step - loss: 0.0821 - accuracy: 0.9724 - val_loss: 0.2425 - val_accuracy: 0.9365
Epoch 24/25
600/600 [==============================] - ETA: 0s - loss: 0.0737 - accuracy: 0.9748
Epoch 24: val_accuracy did not improve from 0.94313
600/600 [==============================] - 288s 479ms/step - loss: 0.0737 - accuracy: 0.9748 - val_loss: 0.2637 - val_accuracy: 0.9394
Epoch 25/25
600/600 [==============================] - ETA: 0s - loss: 0.0796 - accuracy: 0.9734
Epoch 25: val_accuracy did not improve from 0.94313
600/600 [==============================] - 260s 434ms/step - loss: 0.0796 - accuracy: 0.9734 - val_loss: 0.2148 - val_accuracy: 0.9383
ResNet50 history: {'loss': [0.2396712303161621, 0.2174798846244812, 0.20786809921264648, 0.20041413605213165, 0.1959901750087738, 0.1854020357131958, 0.17405623197555542, 0.16890773177146912, 0.15691374242305756, 0.1606941521167755, 0.1490105241537094, 0.13672775030136108, 0.13235069811344147, 0.1262064129114151, 0.11955370754003525, 0.10916277766227722, 0.11027774959802628, 0.10130299627780914, 0.10267951339483261, 0.09262017160654068, 0.09062861651182175, 0.08811036497354507, 0.08211728185415268, 0.07367422431707382, 0.07958114147186279], 'accuracy': [0.9178125262260437, 0.926770806312561, 0.9292708039283752, 0.9315103888511658, 0.9331770539283752, 0.934374988079071, 0.9403125047683716, 0.9421353936195374, 0.9479687213897705, 0.945885419845581, 0.949999988079071, 0.9556770920753479, 0.9531770944595337, 0.9593229293823242, 0.960156261920929, 0.9636458158493042, 0.9627603888511658, 0.9667187333106995, 0.9635416865348816, 0.9688020944595337, 0.9703124761581421, 0.9705208539962769, 0.9723958373069763, 0.9748437404632568, 0.973437488079071], 'val_loss': [0.18568597733974457, 0.18966904282569885, 0.17799971997737885, 0.18571051955223083, 0.17855869233608246, 0.17584966123104095, 0.17211833596229553, 0.1819189190864563, 0.18108156323432922, 0.20555907487869263, 0.19997376203536987, 0.2049049586057663, 0.18125469982624054, 0.18921785056591034, 0.22001881897449493, 0.22551526129245758, 0.2119535356760025, 0.19245654344558716, 0.21713872253894806, 0.20497365295886993, 0.21469788253307343, 0.266775518655777, 0.2424846887588501, 0.2637127637863159, 0.2148461937904358], 'val_accuracy': [0.9381250143051147, 0.9335416555404663, 0.9370833039283752, 0.934374988079071, 0.9397916793823242, 0.9381250143051147, 0.940416693687439, 0.9399999976158142, 0.9383333325386047, 0.9356250166893005, 0.9337499737739563, 0.9379166960716248, 0.9381250143051147, 0.9431250095367432, 0.9331250190734863, 0.9339583516120911, 0.93770831823349, 0.9416666626930237, 0.9366666674613953, 0.9422916769981384, 0.9395833611488342, 0.9352083206176758, 0.9364583492279053, 0.9393749833106995, 0.9383333325386047]}
150/150 [==============================] - 3s 16ms/step
resnet50_acc: 0.9383333333333334
Model: "vgg16"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 input_3 (InputLayer)        [(None, 64, 64, 3)]       0

 block1_conv1 (Conv2D)       (None, 64, 64, 64)        1792

 block1_conv2 (Conv2D)       (None, 64, 64, 64)        36928

 block1_pool (MaxPooling2D)  (None, 32, 32, 64)        0

 block2_conv1 (Conv2D)       (None, 32, 32, 128)       73856

 block2_conv2 (Conv2D)       (None, 32, 32, 128)       147584

 block2_pool (MaxPooling2D)  (None, 16, 16, 128)       0

 block3_conv1 (Conv2D)       (None, 16, 16, 256)       295168

 block3_conv2 (Conv2D)       (None, 16, 16, 256)       590080

 block3_conv3 (Conv2D)       (None, 16, 16, 256)       590080

 block3_pool (MaxPooling2D)  (None, 8, 8, 256)         0

 block4_conv1 (Conv2D)       (None, 8, 8, 512)         1180160

 block4_conv2 (Conv2D)       (None, 8, 8, 512)         2359808

 block4_conv3 (Conv2D)       (None, 8, 8, 512)         2359808

 block4_pool (MaxPooling2D)  (None, 4, 4, 512)         0

 block5_conv1 (Conv2D)       (None, 4, 4, 512)         2359808

 block5_conv2 (Conv2D)       (None, 4, 4, 512)         2359808

 block5_conv3 (Conv2D)       (None, 4, 4, 512)         2359808

 block5_pool (MaxPooling2D)  (None, 2, 2, 512)         0

=================================================================
Total params: 14,714,688
Trainable params: 0
Non-trainable params: 14,714,688
_________________________________________________________________
VGG16 Base model: None
Model: "model_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 input_4 (InputLayer)        [(None, 64, 64, 3)]       0

 data_augmentation (Sequenti  (None, 64, 64, 3)        0
 al)

 tf.__operators__.getitem_1   (None, 64, 64, 3)        0
 (SlicingOpLambda)

 tf.nn.bias_add_1 (TFOpLambd  (None, 64, 64, 3)        0
 a)

 vgg16 (Functional)          (None, 2, 2, 512)         14714688

 global_average_pooling2d (G  (None, 512)              0
 lobalAveragePooling2D)

 dense_2 (Dense)             (None, 128)               65664

 dropout_1 (Dropout)         (None, 128)               0

 dense_3 (Dense)             (None, 10)                1290

=================================================================
Total params: 14,781,642
Trainable params: 66,954
Non-trainable params: 14,714,688
_________________________________________________________________
VGG16 Model: None
Epoch 1/25
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input "contrast_factor" of op 'AdjustContrastv2' expected to be loop invariant.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input "contrast_factor" of op 'AdjustContrastv2' expected to be loop invariant.
600/600 [==============================] - 306s 503ms/step - loss: 4.0731 - accuracy: 0.3857 - val_loss: 1.0004 - val_accuracy: 0.7358
Epoch 2/25
600/600 [==============================] - 313s 521ms/step - loss: 1.4521 - accuracy: 0.6202 - val_loss: 0.6744 - val_accuracy: 0.8023
Epoch 3/25
600/600 [==============================] - 316s 526ms/step - loss: 1.0427 - accuracy: 0.6923 - val_loss: 0.5664 - val_accuracy: 0.8267
Epoch 4/25
600/600 [==============================] - 288s 481ms/step - loss: 0.8834 - accuracy: 0.7297 - val_loss: 0.5040 - val_accuracy: 0.8442
Epoch 5/25
600/600 [==============================] - 225s 375ms/step - loss: 0.7911 - accuracy: 0.7564 - val_loss: 0.4647 - val_accuracy: 0.8558
Epoch 6/25
600/600 [==============================] - 223s 372ms/step - loss: 0.7218 - accuracy: 0.7740 - val_loss: 0.4384 - val_accuracy: 0.8648
Epoch 7/25
600/600 [==============================] - 244s 406ms/step - loss: 0.6562 - accuracy: 0.7932 - val_loss: 0.4134 - val_accuracy: 0.8712
Epoch 8/25
600/600 [==============================] - 257s 429ms/step - loss: 0.6111 - accuracy: 0.8061 - val_loss: 0.4008 - val_accuracy: 0.8763
Epoch 9/25
600/600 [==============================] - 241s 401ms/step - loss: 0.5757 - accuracy: 0.8191 - val_loss: 0.3787 - val_accuracy: 0.8802
Epoch 10/25
600/600 [==============================] - 219s 365ms/step - loss: 0.5533 - accuracy: 0.8247 - val_loss: 0.3657 - val_accuracy: 0.8848
Epoch 11/25
600/600 [==============================] - 218s 364ms/step - loss: 0.5322 - accuracy: 0.8299 - val_loss: 0.3566 - val_accuracy: 0.8875
Epoch 12/25
600/600 [==============================] - 227s 379ms/step - loss: 0.5148 - accuracy: 0.8337 - val_loss: 0.3505 - val_accuracy: 0.8908
Epoch 13/25
600/600 [==============================] - 248s 413ms/step - loss: 0.4896 - accuracy: 0.8458 - val_loss: 0.3413 - val_accuracy: 0.8935
Epoch 14/25
600/600 [==============================] - 228s 379ms/step - loss: 0.4730 - accuracy: 0.8458 - val_loss: 0.3374 - val_accuracy: 0.8931
Epoch 15/25
600/600 [==============================] - 235s 391ms/step - loss: 0.4576 - accuracy: 0.8492 - val_loss: 0.3313 - val_accuracy: 0.8929
Epoch 16/25
600/600 [==============================] - 221s 368ms/step - loss: 0.4579 - accuracy: 0.8483 - val_loss: 0.3265 - val_accuracy: 0.8975
Epoch 17/25
600/600 [==============================] - 242s 404ms/step - loss: 0.4404 - accuracy: 0.8572 - val_loss: 0.3237 - val_accuracy: 0.8969
Epoch 18/25
600/600 [==============================] - 250s 417ms/step - loss: 0.4293 - accuracy: 0.8610 - val_loss: 0.3196 - val_accuracy: 0.8985
Epoch 19/25
600/600 [==============================] - 298s 498ms/step - loss: 0.4250 - accuracy: 0.8614 - val_loss: 0.3146 - val_accuracy: 0.8990
Epoch 20/25
600/600 [==============================] - 231s 385ms/step - loss: 0.4189 - accuracy: 0.8608 - val_loss: 0.3125 - val_accuracy: 0.9013
Epoch 21/25
600/600 [==============================] - 353s 589ms/step - loss: 0.4067 - accuracy: 0.8687 - val_loss: 0.3072 - val_accuracy: 0.9035
Epoch 22/25
600/600 [==============================] - 338s 563ms/step - loss: 0.3971 - accuracy: 0.8675 - val_loss: 0.3098 - val_accuracy: 0.9017
Epoch 23/25
600/600 [==============================] - 226s 377ms/step - loss: 0.3919 - accuracy: 0.8702 - val_loss: 0.3022 - val_accuracy: 0.9038
Epoch 24/25
600/600 [==============================] - 235s 393ms/step - loss: 0.3871 - accuracy: 0.8740 - val_loss: 0.2984 - val_accuracy: 0.9069
Epoch 25/25
600/600 [==============================] - 209s 348ms/step - loss: 0.3797 - accuracy: 0.8754 - val_loss: 0.2975 - val_accuracy: 0.9050
VGG16 phase A history: {'loss': [4.073085308074951, 1.4521182775497437, 1.0427238941192627, 0.8834109306335449, 0.7910825610160828, 0.7218091487884521, 0.6561704277992249, 0.6110968589782715, 0.57574063539505, 0.5533209443092346, 0.5321959257125854, 0.5148483514785767, 0.48957744240760803, 0.4730187952518463, 0.4576246738433838, 0.4578869044780731, 0.44035089015960693, 0.4292677342891693, 0.425033837556839, 0.4189433157444, 0.4067002832889557, 0.3970917761325836, 0.39190101623535156, 0.3870738744735718, 0.37970420718193054], 'accuracy': [0.3856770694255829, 0.6201562285423279, 0.6922916769981384, 0.729687511920929, 0.7564062476158142, 0.774010419845581, 0.79317706823349, 0.8060937523841858, 0.8190624713897705, 0.8247395753860474, 0.8298958539962769, 0.8336979150772095, 0.8458333611488342, 0.8458333611488342, 0.8492187261581421, 0.8482812643051147, 0.8571875095367432, 0.8610416650772095, 0.8613541722297668, 0.8607812523841858, 0.8686979413032532, 0.8675000071525574, 0.8702083230018616, 0.8739583492279053, 0.8753646016120911], 'val_loss': [1.0004421472549438, 0.6744294762611389, 0.5664055347442627, 0.5039963126182556, 0.4647034704685211, 0.438441663980484, 0.41337814927101135, 0.40079259872436523, 0.3787325620651245, 0.36571773886680603, 0.3566226661205292, 0.35051023960113525, 0.3413461744785309, 0.33735403418540955, 0.3313148617744446, 0.3265046775341034, 0.32374250888824463, 0.31958895921707153, 0.3146273195743561, 0.3124759793281555, 0.30716434121131897, 0.3097783327102661, 0.30223405361175537, 0.2984037697315216, 0.2975122928619385], 'val_accuracy': [0.7358333468437195, 0.8022916913032532, 0.8266666531562805, 0.8441666960716248, 0.8558333516120911, 0.8647916913032532, 0.8712499737739563, 0.8762500286102295, 0.8802083134651184, 0.8847916722297668, 0.887499988079071, 0.89083331823349, 0.893541693687439, 0.8931249976158142, 0.8929166793823242, 0.8974999785423279, 0.8968750238418579, 0.8985416889190674, 0.8989583253860474, 0.9012500047683716, 0.9035416841506958, 0.9016666412353516, 0.9037500023841858, 0.9068750143051147, 0.9049999713897705]}
Epoch 1/25
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input "contrast_factor" of op 'AdjustContrastv2' expected to be loop invariant.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input "contrast_factor" of op 'AdjustContrastv2' expected to be loop invariant.
600/600 [==============================] - ETA: 0s - loss: 0.4440 - accuracy: 0.8708
Epoch 1: val_accuracy improved from -inf to 0.90625, saving model to models\vgg16.h5
600/600 [==============================] - 237s 387ms/step - loss: 0.4440 - accuracy: 0.8708 - val_loss: 0.3097 - val_accuracy: 0.9062
Epoch 2/25
600/600 [==============================] - ETA: 0s - loss: 0.2707 - accuracy: 0.9191
Epoch 2: val_accuracy improved from 0.90625 to 0.91312, saving model to models\vgg16.h5
600/600 [==============================] - 248s 413ms/step - loss: 0.2707 - accuracy: 0.9191 - val_loss: 0.3026 - val_accuracy: 0.9131
Epoch 3/25
600/600 [==============================] - ETA: 0s - loss: 0.2159 - accuracy: 0.9346
Epoch 3: val_accuracy improved from 0.91312 to 0.93854, saving model to models\vgg16.h5
600/600 [==============================] - 244s 406ms/step - loss: 0.2159 - accuracy: 0.9346 - val_loss: 0.2427 - val_accuracy: 0.9385
Epoch 4/25
600/600 [==============================] - ETA: 0s - loss: 0.1849 - accuracy: 0.9452
Epoch 4: val_accuracy did not improve from 0.93854
600/600 [==============================] - 241s 402ms/step - loss: 0.1849 - accuracy: 0.9452 - val_loss: 0.1900 - val_accuracy: 0.9377
Epoch 5/25
600/600 [==============================] - ETA: 0s - loss: 0.1808 - accuracy: 0.9480
Epoch 5: val_accuracy did not improve from 0.93854
600/600 [==============================] - 240s 401ms/step - loss: 0.1808 - accuracy: 0.9480 - val_loss: 0.2494 - val_accuracy: 0.9281
Epoch 6/25
600/600 [==============================] - ETA: 0s - loss: 0.1562 - accuracy: 0.9540
Epoch 6: val_accuracy did not improve from 0.93854
600/600 [==============================] - 183s 305ms/step - loss: 0.1562 - accuracy: 0.9540 - val_loss: 0.2301 - val_accuracy: 0.9375
Epoch 7/25
600/600 [==============================] - ETA: 0s - loss: 0.1365 - accuracy: 0.9597
Epoch 7: val_accuracy did not improve from 0.93854
600/600 [==============================] - 181s 301ms/step - loss: 0.1365 - accuracy: 0.9597 - val_loss: 0.3496 - val_accuracy: 0.9112
Epoch 8/25
600/600 [==============================] - ETA: 0s - loss: 0.1337 - accuracy: 0.9609
Epoch 8: val_accuracy did not improve from 0.93854
600/600 [==============================] - 182s 304ms/step - loss: 0.1337 - accuracy: 0.9609 - val_loss: 0.2890 - val_accuracy: 0.9237
Epoch 9/25
600/600 [==============================] - ETA: 0s - loss: 0.1160 - accuracy: 0.9650
Epoch 9: val_accuracy improved from 0.93854 to 0.94354, saving model to models\vgg16.h5
600/600 [==============================] - 184s 306ms/step - loss: 0.1160 - accuracy: 0.9650 - val_loss: 0.2230 - val_accuracy: 0.9435
Epoch 10/25
600/600 [==============================] - ETA: 0s - loss: 0.1078 - accuracy: 0.9682
Epoch 10: val_accuracy did not improve from 0.94354
600/600 [==============================] - 190s 317ms/step - loss: 0.1078 - accuracy: 0.9682 - val_loss: 0.3063 - val_accuracy: 0.9235
Epoch 11/25
600/600 [==============================] - ETA: 0s - loss: 0.1103 - accuracy: 0.9683
Epoch 11: val_accuracy did not improve from 0.94354
600/600 [==============================] - 183s 306ms/step - loss: 0.1103 - accuracy: 0.9683 - val_loss: 0.3500 - val_accuracy: 0.9217
Epoch 12/25
600/600 [==============================] - ETA: 0s - loss: 0.0954 - accuracy: 0.9707
Epoch 12: val_accuracy did not improve from 0.94354
600/600 [==============================] - 183s 305ms/step - loss: 0.0954 - accuracy: 0.9707 - val_loss: 0.4667 - val_accuracy: 0.9058
Epoch 13/25
600/600 [==============================] - ETA: 0s - loss: 0.1050 - accuracy: 0.9702
Epoch 13: val_accuracy did not improve from 0.94354
600/600 [==============================] - 184s 307ms/step - loss: 0.1050 - accuracy: 0.9702 - val_loss: 0.4500 - val_accuracy: 0.9119
Epoch 14/25
600/600 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.9739
Epoch 14: val_accuracy did not improve from 0.94354
600/600 [==============================] - 184s 306ms/step - loss: 0.0879 - accuracy: 0.9739 - val_loss: 0.2936 - val_accuracy: 0.9281
Epoch 15/25
600/600 [==============================] - ETA: 0s - loss: 0.0694 - accuracy: 0.9789
Epoch 15: val_accuracy improved from 0.94354 to 0.94896, saving model to models\vgg16.h5
600/600 [==============================] - 184s 306ms/step - loss: 0.0694 - accuracy: 0.9789 - val_loss: 0.2082 - val_accuracy: 0.9490
Epoch 16/25
600/600 [==============================] - ETA: 0s - loss: 0.0893 - accuracy: 0.9745
Epoch 16: val_accuracy improved from 0.94896 to 0.95146, saving model to models\vgg16.h5
600/600 [==============================] - 184s 307ms/step - loss: 0.0893 - accuracy: 0.9745 - val_loss: 0.2149 - val_accuracy: 0.9515
Epoch 17/25
600/600 [==============================] - ETA: 0s - loss: 0.0832 - accuracy: 0.9760
Epoch 17: val_accuracy improved from 0.95146 to 0.95479, saving model to models\vgg16.h5
600/600 [==============================] - 182s 303ms/step - loss: 0.0832 - accuracy: 0.9760 - val_loss: 0.1891 - val_accuracy: 0.9548
Epoch 18/25
600/600 [==============================] - ETA: 0s - loss: 0.0623 - accuracy: 0.9820
Epoch 18: val_accuracy did not improve from 0.95479
600/600 [==============================] - 184s 307ms/step - loss: 0.0623 - accuracy: 0.9820 - val_loss: 0.2669 - val_accuracy: 0.9519
Epoch 19/25
600/600 [==============================] - ETA: 0s - loss: 0.0724 - accuracy: 0.9793
Epoch 19: val_accuracy did not improve from 0.95479
600/600 [==============================] - 186s 310ms/step - loss: 0.0724 - accuracy: 0.9793 - val_loss: 0.3022 - val_accuracy: 0.9344
Epoch 20/25
600/600 [==============================] - ETA: 0s - loss: 0.0761 - accuracy: 0.9787
Epoch 20: val_accuracy did not improve from 0.95479
600/600 [==============================] - 183s 305ms/step - loss: 0.0761 - accuracy: 0.9787 - val_loss: 0.2086 - val_accuracy: 0.9544
Epoch 21/25
600/600 [==============================] - ETA: 0s - loss: 0.0634 - accuracy: 0.9801
Epoch 21: val_accuracy did not improve from 0.95479
600/600 [==============================] - 184s 306ms/step - loss: 0.0634 - accuracy: 0.9801 - val_loss: 0.3460 - val_accuracy: 0.9340
Epoch 22/25
600/600 [==============================] - ETA: 0s - loss: 0.0711 - accuracy: 0.9811
Epoch 22: val_accuracy did not improve from 0.95479
600/600 [==============================] - 185s 308ms/step - loss: 0.0711 - accuracy: 0.9811 - val_loss: 0.2673 - val_accuracy: 0.9463
Epoch 23/25
600/600 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 0.9823
Epoch 23: val_accuracy did not improve from 0.95479
600/600 [==============================] - 183s 305ms/step - loss: 0.0645 - accuracy: 0.9823 - val_loss: 0.3258 - val_accuracy: 0.9335
Epoch 24/25
600/600 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.9854
Epoch 24: val_accuracy improved from 0.95479 to 0.95542, saving model to models\vgg16.h5
600/600 [==============================] - 185s 308ms/step - loss: 0.0506 - accuracy: 0.9854 - val_loss: 0.1990 - val_accuracy: 0.9554
Epoch 25/25
600/600 [==============================] - ETA: 0s - loss: 0.0514 - accuracy: 0.9846
Epoch 25: val_accuracy did not improve from 0.95542
600/600 [==============================] - 185s 308ms/step - loss: 0.0514 - accuracy: 0.9846 - val_loss: 0.4247 - val_accuracy: 0.9308
VGG16 history: {'loss': [0.44398924708366394, 0.2707001864910126, 0.21586155891418457, 0.184902623295784, 0.18081709742546082, 0.15621839463710785, 0.1365230232477188, 0.133721724152565, 0.11600825935602188, 0.1077684760093689, 0.11029345542192459, 0.09544003754854202, 0.10500838607549667, 0.08788290619850159, 0.06939776241779327, 0.08929797261953354, 0.08323636651039124, 0.06234624981880188, 0.07240911573171616, 0.07609318941831589, 0.06344803422689438, 0.07109258323907852, 0.06449571251869202, 0.05063929781317711, 0.051446251571178436], 'accuracy': [0.8707812428474426, 0.9191145896911621, 0.934583306312561, 0.9451562762260437, 0.9479687213897705, 0.9540104269981384, 0.9596874713897705, 0.9608854055404663, 0.9649999737739563, 0.968177080154419, 0.9682812690734863, 0.9707291722297668, 0.9701562523841858, 0.9738541841506958, 0.9789062738418579, 0.9744791388511658, 0.975989580154419, 0.9819791913032532, 0.9793229103088379, 0.9787499904632568, 0.9801041483879089, 0.9810937643051147, 0.9823437333106995, 0.9854166507720947, 0.98458331823349], 'val_loss': [0.3096930682659149, 0.3026304244995117, 0.2426517754793167, 0.19003407657146454, 0.24944518506526947, 0.23009872436523438, 0.3496340811252594, 0.2889727056026459, 0.22302253544330597, 0.3063085973262787, 0.34996628761291504, 0.46668288111686707, 0.4499897360801697, 0.2935568690299988, 0.20818203687667847, 0.2148502916097641, 0.1890757828950882, 0.26694566011428833, 0.3021792471408844, 0.20856903493404388, 0.34599149227142334, 0.26725611090660095, 0.3257759213447571, 0.19903460144996643, 0.42469143867492676], 'val_accuracy': [0.90625, 0.9131249785423279, 0.9385416507720947, 0.93770831823349, 0.9281250238418579, 0.9375, 0.9112499952316284, 0.9237499833106995, 0.9435416460037231, 0.9235416650772095, 0.92166668176651, 0.9058333039283752, 0.9118750095367432, 0.9281250238418579, 0.9489583373069763, 0.9514583349227905, 0.9547916650772095, 0.9518749713897705, 0.934374988079071, 0.9543750286102295, 0.9339583516120911, 0.9462500214576721, 0.9335416555404663, 0.9554166793823242, 0.9308333396911621]}
150/150 [==============================] - 2s 13ms/step
vgg16_acc: 0.9308333333333333
150/150 [==============================] - 2s 13ms/step
vgg16 prediction values: [[7.7860472e-31 6.3533612e-37 4.1097328e-20 ... 1.3901202e-10
  8.8680121e-20 0.0000000e+00]
 [2.4515998e-21 4.5790521e-15 1.0000000e+00 ... 2.9471266e-13
  9.8743806e-15 3.9542930e-37]
 [3.6867095e-28 0.0000000e+00 8.5832173e-34 ... 0.0000000e+00
  1.0000000e+00 0.0000000e+00]
 ...
 [1.2705803e-11 5.7214788e-10 9.9999642e-01 ... 1.3735577e-07
  7.3539166e-09 7.4091876e-21]
 [7.4658221e-15 6.6457347e-16 1.3047842e-09 ... 1.0567762e-02
  4.7374982e-11 5.0715060e-26]
 [4.5336953e-01 4.8977614e-04 2.4255902e-02 ... 3.6871652e-04
  4.8516518e-03 4.6234553e-07]]
vgg16 prediction type: <class 'numpy.ndarray'>
150/150 [==============================] - 2s 11ms/step
resnet50 prediction values: [[1.7677566e-12 3.1504039e-13 1.5244824e-09 ... 3.6112074e-06
  4.8511728e-10 4.3667446e-23]
 [4.6634126e-05 7.2168302e-07 9.9705362e-01 ... 7.3063798e-05
  2.8635399e-05 4.8832418e-12]
 [1.4929981e-03 3.4222418e-07 2.0926371e-05 ... 3.0129002e-07
  9.9791116e-01 2.7807398e-13]
 ...
 [2.3777156e-06 1.5912202e-06 9.9474096e-01 ... 3.6228630e-06
  8.5652665e-08 3.7901339e-13]
 [8.6954765e-13 1.0526189e-11 5.7479403e-09 ... 2.9546488e-04
  1.5127856e-10 7.8561519e-22]
 [9.8732823e-01 8.4541256e-08 8.8248271e-06 ... 2.3321661e-08
  1.0348704e-03 3.2848247e-12]]
resnet50 prediction type: <class 'numpy.ndarray'>
final prediction values: [4 2 8 ... 2 4 0]
ensemble_acc: 0.96625
VGG16 Accuracy:     0.9308
ResNet50 Accuracy:  0.9383
Ensemble(Soft Voting) Accuracy:  0.9663

Process finished with exit code 0